<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="sean lee`s blog" />










<meta name="description" content="NLP / DL / Python / C++ | 爱我所爱">
<meta property="og:type" content="website">
<meta property="og:title" content="明天探索者">
<meta property="og:url" content="http://seanlee97.github.io/index.html">
<meta property="og:site_name" content="明天探索者">
<meta property="og:description" content="NLP / DL / Python / C++ | 爱我所爱">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="明天探索者">
<meta name="twitter:description" content="NLP / DL / Python / C++ | 爱我所爱">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: "",
      labels: ""
    }
  };
</script>



  <link rel="canonical" href="http://seanlee97.github.io/"/>





  <title>明天探索者</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">明天探索者</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/10/01/常用的梯度下降优化算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/10/01/常用的梯度下降优化算法/" itemprop="url">常用的梯度下降优化算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-01T10:33:17+08:00">
                2018-10-01
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/10/01/常用的梯度下降优化算法/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/10/01/常用的梯度下降优化算法/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>梯度下降是常用的优化方式，具体的算法有：</p>
<ul>
<li>梯度下降法
<ul>
<li>批梯度下降(Batch Gradient Descent, BGD)</li>
<li>随机梯度下降(Stochastic Gradient Decent, SGD)</li>
<li>小批量梯度下降(Mini-Batch Gradient Decent, MBGD)</li>
</ul></li>
<li>梯度下降优化
<ul>
<li>动量梯度下降(Gradient Descent with Momentum)</li>
<li>均方根支(Root Mean Square Prop, RMSprop)</li>
<li>自适应矩估计(Adaptive Moment Estimation, Adam)</li>
</ul></li>
</ul>
<p>本文主要简单介绍上述优化方法</p>
<h2 id="知识储备">知识储备</h2>
<h3 id="梯度下降法">梯度下降法</h3>
<p>梯度下降法(gradient descent)是求解无约束最优化问题的一种最常用方法，它是一种迭代算法，每一步需要求解目标函数的梯度向量。它的优点是实现简单，缺点是一般情况下不能保证解是全局最优的</p>
<h4 id="导数">导数</h4>
<p><img src="/images/posts/gradient_descent/01.png"></p>
<p><strong>方向导数定义：</strong> 如上图, <span class="math inline">\(p{}&#39;\)</span> 沿着 <span class="math inline">\(l\)</span> 趋于 <span class="math inline">\(p\)</span> 时，如果函数的增量 <span class="math inline">\(f(x+\Delta x, y+\Delta y) - f(x, y)\)</span> 与 <span class="math inline">\(pp{}&#39;\)</span> 两点间的距离 <span class="math inline">\(\rho = \sqrt{(\Delta x)^{2} + (\Delta y)^{2}}\)</span> 的比值的极限存在，则称此极限为 <span class="math inline">\(p\)</span> 沿着 <span class="math inline">\(l\)</span> 方向的导数，记作</p>
<p><span class="math display">\[\frac{\partial f}{\partial l} = \lim_{\rho \rightarrow 0} \frac{f(x+\Delta x, y+\Delta y) - f(x, y)}{\rho } \\\\
\tag{1}\]</span></p>
<p>更一般的，对于函数 <span class="math inline">\(f(x)\)</span> , 在 <span class="math inline">\(x_{0}\)</span> 处的导数为</p>
<p><span class="math display">\[\begin{align*}
f{}&#39;(x_{0}) &amp; = \lim_{x \rightarrow x_{0}} \frac{f(x) - f(x_{0})}{x-x_{0}} \\\\
&amp; = \lim_{\Delta x \rightarrow 0} \frac{f(x_{0}+\Delta x) - f(x_{0})}{\Delta x} \\\\
\tag{2}
\end{align*}\]</span></p>
<h4 id="梯度">梯度</h4>
<p>函数在某点的梯度的方向与取得最大方向导数的方向一致，而它的模为方向导数的最大值</p>
<p><strong>定义：</strong> 设函数 <span class="math inline">\(z = f(x, y)\)</span> 在平面区域D内，具有<strong>一阶连续偏导数</strong>，则对于每一点 <span class="math inline">\(p(x, y) \in D\)</span> , 都可定义一个向量 <span class="math inline">\(\frac{\partial f}{\partial x} \underset{i}{\rightarrow} + \frac{\partial f}{\partial y} \underset{j}{\rightarrow}\)</span> 满足梯度的条件，则这向量称为 <span class="math inline">\(z=f(x, y)\)</span> 在点 <span class="math inline">\(p(x, y)\)</span> 的梯度，记作</p>
<p><span class="math display">\[\begin{align*}gradf(x, y) = \frac{\partial f}{\partial x} \underset{i}{\rightarrow} + \frac{\partial f}{\partial y} \underset{j}{\rightarrow} \\\\
\tag{3}
\end{align*}\]</span></p>
<h3 id="牛顿法和拟牛顿法">牛顿法和拟牛顿法</h3>
<p>牛顿法和拟牛顿法也是求解无约束最优化问题的常用方法，它的优点是收敛速度快。一般用来求解大规模数据的优化问题</p>
<h4 id="海森矩阵hessian-matrix">海森矩阵(Hessian Matrix)</h4>
<p>海森矩阵是一个<strong>多变量实值函数</strong>的<strong>二阶偏导数</strong>组成的<strong>方块矩阵</strong>,假设有一实数函数 <span class="math inline">\(f(x_{1}, x_{2}, ..., x_{n})\)</span> ，如果 <span class="math inline">\(f\)</span> 所有的二阶偏导数都存在，那么海森矩阵为对称矩阵， <span class="math inline">\(f\)</span> 的海森矩阵的第 <span class="math inline">\(ij\)</span> 项即为 <span class="math inline">\(H(f)_{ij}(x) = D_{i}D_{j}f(x)\)</span> ，其中 <span class="math inline">\(x=(x_{1}, x_{2}, ..., x_{n})\)</span> 即</p>
<p><img src="/images/posts/gradient_descent/02.png"></p>
<p>更一般的海森矩阵也可表示为</p>
<p><span class="math display">\[\begin{align*}
H(x) = \begin{bmatrix}
\frac{\partial ^{2} f}{\partial x_{i} \partial x_{j}}
\end{bmatrix} _{n\times n} \\\\
\tag{4}
\end{align*}\]</span></p>
<h4 id="正定半正定矩阵">正定半正定矩阵</h4>
<ul>
<li>正定矩阵：所有特征值大于0 (&gt;0)</li>
<li>负定矩阵：所有特征值小于0 (&lt;0)</li>
<li>半正定矩阵： 所有特征值为非负（&gt;=0）</li>
<li>半负定矩阵：所有特征值为非正（&lt;=0）</li>
<li>不定矩阵：特征值有正有负</li>
</ul>
<h4 id="牛顿法">牛顿法</h4>
<p>牛顿法是迭代算法，每一步需要求解目标函数的海森矩阵的逆矩阵，计算方法比较复杂，这里不详细叙述，具体可阅读<a href="https://en.wikipedia.org/wiki/Newton%27s_method_in_optimization" target="_blank" rel="noopener">Newton’s method in optimization</a></p>
<h4 id="拟牛顿法">拟牛顿法</h4>
<p>拟牛顿法是通过正定矩阵近似的海森矩阵的逆矩阵来简化牛顿法的计算过程，常用算法有 <code>DFP</code>, <code>BFGS</code></p>
<h3 id="等高线">等高线</h3>
<p>在几何上 <span class="math inline">\(z=f(x, y)\)</span> 表示一个曲面，当曲面被平面 <span class="math inline">\(z = c\)</span> 所截，得到的曲线 <span class="math inline">\(\left\{\begin{matrix} z = f(x, y) \\\\ z = c \end{matrix}\right.\)</span> 在 <span class="math inline">\(xoy\)</span> 面上的投影方程 <span class="math inline">\(f(x, y)=c\)</span> 称为等值线，几何上称为等高线</p>
<p><img src="/images/posts/gradient_descent/03.png"></p>
<h2 id="梯度下降法-1">梯度下降法</h2>
<h3 id="批梯度下降batch-gradient-descent-bgd">批梯度下降(Batch Gradient Descent, BGD)</h3>
<p>批梯度下降法在更新参数时使用所有样本来进行更新</p>
<p><span class="math display">\[\begin{align*}
J(w, b) = \frac{1}{m}\sum_{i=1}^{m} L (\hat{y^{(i)}}, y^{(i)}) + \frac{\lambda }{2m}\sum \left \| w \right \|_{F}^{2} \\\\
w_{j} := w_{j} - \alpha \frac{\partial J(w, b)}{\partial w_{j}} \\\\
b_{j} := b_{j} - \alpha \frac{\partial J(w, b)}{\partial b_{j}} \\\\
\tag{5}
\end{align*}\]</span></p>
<p>其中 <span class="math inline">\(\frac{\lambda }{2m}\sum \left \| w \right \|_{F}^{2}\)</span> 是L2正则项, <span class="math inline">\(\alpha\)</span> 是学习速率 <code>learning rate</code></p>
<h4 id="bgd的梯度下降图">BGD的梯度下降图</h4>
<p><img src="/images/posts/gradient_descent/04.png"></p>
<h4 id="bgd的优缺点">BGD的优缺点</h4>
<ul>
<li>优点：最小化<strong>所有训练样本</strong>的损失函数得到全局最优</li>
<li>缺点：当样本数目很多时，训练过程很慢</li>
</ul>
<h4 id="python伪代码">Python伪代码</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="comment"># 是对每个epoch的所有数据进行计算的</span></span><br><span class="line">    grad = loss_fn(*args, **kwargs)</span><br><span class="line">    params = params - learning_rate * grad</span><br></pre></td></tr></table></figure>
<h3 id="随机梯度下降stochastic-gradient-decent-sgd">随机梯度下降(Stochastic Gradient Decent, SGD)</h3>
<p>每次通过一个样本来迭代更新</p>
<p><span class="math display">\[\begin{align*}
J(w, b) = L (\hat{y^{(i)}}, y^{(i)}) + \frac{\lambda }{2}\sum \left \| w \right \|_{F}^{2} \\\\
w_{j} := w_{j} - \alpha \frac{\partial J(w, b)}{\partial w_{j}} \\\\
b_{j} := b_{j} - \alpha \frac{\partial J(w, b)}{\partial b_{j}} \\\\
\tag{6}
\end{align*}\]</span></p>
<h4 id="sgd的梯度下降图">SGD的梯度下降图</h4>
<p><img src="/images/posts/gradient_descent/05.png"></p>
<h4 id="sgd的优缺点">SGD的优缺点</h4>
<ul>
<li>优点：训练速度快</li>
<li>缺点：不易找到全局最优</li>
</ul>
<h4 id="python伪代码-1">Python伪代码</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    shuffle(data)</span><br><span class="line">    <span class="keyword">for</span> example <span class="keyword">in</span> data:</span><br><span class="line">        grad = loss_fn(*args, **kwarga)</span><br><span class="line">        params = params - learning_rate * grad</span><br></pre></td></tr></table></figure>
<h3 id="小批量梯度下降算法mini-batch-gradient-decent-mbgd">小批量梯度下降算法(Mini-Batch Gradient Decent, MBGD)</h3>
<p>对随机梯度下降和批梯度下降进行了折衷， 每次用 <span class="math inline">\(t (1 &lt; t &lt; m)\)</span> 个样本进行更新</p>
<p><span class="math display">\[\begin{align*}
J(w, b) = \frac{1}{k}\sum_{i=1}^{k} L (\hat{y^{(i)}}, y^{(i)}) + \frac{\lambda }{2k}\sum \left \| w \right \|_{F}^{2} \\\\
w_{j} := w_{j} - \alpha \frac{\partial J(w, b)}{\partial w_{j}} \\\\
b_{j} := b_{j} - \alpha \frac{\partial J(w, b)}{\partial b_{j}} \\\\
\tag{7}
\end{align*}\]</span></p>
<h4 id="mbgd的梯度下降图">MBGD的梯度下降图</h4>
<p><img src="/images/posts/gradient_descent/06.png"></p>
<h4 id="python伪代码-2">Python伪代码</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    shuffle(data)</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> next_batch(data, batch_size):</span><br><span class="line">        grad = loss_fn(*args, **kwargs)</span><br><span class="line">        params = params - learning_rate * grad</span><br></pre></td></tr></table></figure>
<h2 id="梯度下降优化">梯度下降优化</h2>
<p>优化的方式一般有两种：</p>
<ul>
<li>算法</li>
<li>优化方法的选择，比如大数据量下采用牛顿法/拟牛顿法进行优化</li>
</ul>
<h3 id="指数加权平均">指数加权平均</h3>
<p>是一种常用的序列数据处理方式</p>
<p><span class="math display">\[\begin{align*}
S_{t} = \begin{cases}
Y_{1} &amp; \text{ if } t=1\\ 
\beta S_{t-1} + (1-\beta)Y_{t} &amp; \text{ if } t&gt;1 
\end{cases} \\\\
\tag{8}
\end{align*}\]</span></p>
<p><span class="math inline">\(Y_{t}\)</span> 为 <span class="math inline">\(t\)</span>下的实际值， <span class="math inline">\(S_{t}\)</span> 为 <span class="math inline">\(t\)</span> 下加权平均后的值， <span class="math inline">\(\beta\)</span> 为权重</p>
<h3 id="动量梯度下降gradient-descent-with-momentum">动量梯度下降（Gradient Descent with Momentum）</h3>
<p>是计算梯度的指数加权平均数，并利用该值来更新参数值</p>
<p><span class="math display">\[\begin{align*}
&amp; \upsilon_{dw} = \beta \upsilon_{dw} + (1-\beta) dw \\\\
&amp; \upsilon_{db} = \beta \upsilon_{db} + (1-\beta) db \\\\
&amp; w := w - \alpha \upsilon_{dw} \\\\
&amp; b := b - \alpha \upsilon_{db} \\\\
\tag{9}
\end{align*}\]</span></p>
<p>SGD 在局部沟壑中很容易发生振荡，所以在这种情况下下降速度会很慢，而动量能在一定程度上抑制这种震荡，使得SGD的下降更平稳</p>
<p>如下图为不加Momentum和加了Momentum的区别</p>
<img src="/images/posts/gradient_descent/07.gif">
<p align="center">
未加Momentum的SGD
</p>
<img src="/images/posts/gradient_descent/08.gif">
<p align="center">
加了Momentum的SGD
</p>
<p><strong>特点：</strong>当前后梯度方向一致时，Momentum梯度下降能够<strong>加速学习</strong>；前后梯度方向不一致时,Momentum梯度下降能够<strong>抑制震荡</strong></p>
<h3 id="均方根支root-mean-square-prop-rmsprop">均方根支(Root Mean Square Prop, RMSProp)</h3>
<p>在梯度进行指数加权平均的基础上引入了平方和平方根</p>
<p><span class="math display">\[\begin{align*}
&amp; S_{dw} = \beta S_{dw} + (1-\beta) dw^{2} \\\\
&amp; S_{db} = \beta S_{db} + (1-\beta) db^{2} \\\\
&amp; w := w - \alpha \frac{dw}{\sqrt{S_{dw} + \epsilon }} \\\\
&amp; b := b - \alpha \frac{dw}{\sqrt{S_{db} + \epsilon }} \\\\
\tag{10}
\end{align*}\]</span></p>
<p><span class="math inline">\(\epsilon\)</span> 一般值很小，主要是用来提高数值稳定性，防止分母过小</p>
<p><strong>特点：</strong> 当 <span class="math inline">\(dw\)</span> 或 <span class="math inline">\(db\)</span> 较大时，<span class="math inline">\(dw^{2}\)</span> 和 <span class="math inline">\(db^{2}\)</span> 也会较大，因此 <span class="math inline">\(S_{dw}\)</span> <span class="math inline">\(S_{db}\)</span> 也是较大的，最终使得 <span class="math inline">\(\frac{dw}{\sqrt{S_{dw} + \epsilon}}\)</span> <span class="math inline">\(\frac{db}{\sqrt{S_{db} + \epsilon}}\)</span> 较小，这也减少了振荡</p>
<h3 id="自适应矩估计adaptive-moment-estimation-adam">自适应矩估计(Adaptive Moment Estimation, Adam)</h3>
<p>可以认为是 <code>Momentum</code> 和 <code>RMSProp</code> 的结合</p>
<p><span class="math display">\[\begin{align*}
&amp; \upsilon_{dw} = \beta_{1} \upsilon_{dw} + (1-\beta _{1}) dw, \upsilon _{db} = \beta_{1} \upsilon_{db} + (1-\beta _{1}) db \\\\
&amp; S_{dw} = \beta_{2} S_{dw} + (1-\beta _{2}) dw^{2}, S_{db} = \beta_{2} S_{db} + (1-\beta _{2}) db^{2} \\\\
&amp; \upsilon_{dw}^{correct} = \frac{\upsilon _{dw}}{1-\beta_{1}^{t}}, \upsilon_{db}^{correct} = \frac{\upsilon_{db}}{1-\beta_{1}^{t}} \\\\
&amp; S_{dw}^{correct} = \frac{S_{dw}}{1-\beta_{2}^{t}}, S_{db}^{correct} = \frac{S_{db}}{1-\beta_{2}^{t}} \\\\
&amp; w := w - \alpha \frac{\upsilon_{dw}^{correct}}{\sqrt{S_{dw}^{correct}} + \epsilon} \\\\
&amp; b := b - \alpha \frac{\upsilon_{db}^{correct}}{\sqrt{S_{db}^{correct}} + \epsilon} \\\\
\tag{11}
\end{align*}\]</span></p>
<p><span class="math inline">\(\beta _{1}\)</span>为第一阶矩，<span class="math inline">\(\beta _{2}\)</span> 为第二阶矩</p>
<h3 id="各优化算法的比较">各优化算法的比较</h3>
<p><img src="/images/posts/gradient_descent/09.gif"> <img src="/images/posts/gradient_descent/10.gif"></p>
<h2 id="reference">Reference</h2>
<p>[1]李航《统计学习方法》</p>
<p>[2] https://wenku.baidu.com/view/d3dbe40903d8ce2f00662358.html</p>
<p>[3] https://wenku.baidu.com/view/23aca9eab8f67c1cfad6b84f.html</p>
<p>[4] https://zh.wikipedia.org/wiki/%E6%B5%B7%E6%A3%AE%E7%9F%A9%E9%98%B5</p>
<p>[5] http://binweber.top/2017/10/06/deep_learning_4/</p>
<p>[6] http://ruder.io/optimizing-gradient-descent/</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/09/09/简单理解上帝算法EM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/09/简单理解上帝算法EM/" itemprop="url">简单理解"上帝算法"EM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-09T20:00:07+08:00">
                2018-09-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/09/简单理解上帝算法EM/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/09/09/简单理解上帝算法EM/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>EM(Expectation Maximization, 期望最大)算法也称“上帝算法”，能称为“上帝”可见它有多牛掰。</p>
<p>EM的原理很简单但真正理解起来是挺痛苦的一件事，本文以凡人视角尝试理解上帝本意。</p>
<h2 id="知识储备">知识储备</h2>
<h3 id="kl距离">KL距离</h3>
<p>KL距离又称相对熵(relative entropy)，用来衡量空间上两个概率分布 <span class="math inline">\(P(x)\)</span>，<span class="math inline">\(Q(x)\)</span> 的相对差距的测度（通俗的说就是两个概率分布的距离）</p>
<p><span class="math display">\[\begin{align*}
D_{KL}(P||Q) &amp; = \sum_{i} P(i)log\ \frac{P(i)}{Q(i)} \\
&amp; = \sum_{i} P(i) log\ P(i) - \sum_{i} P(i) log\  Q(i) \\
&amp; = E_{P}(log\ P(i)) - E_{P}(log\ Q(i))
\end{align*} \tag{1}\]</span></p>
<p><span class="math inline">\((1)\)</span> 式便于理解“距离”的概念，因为A, B两点的距离我们一般表示为 <span class="math inline">\(|A-B|\)</span> ，当 <span class="math inline">\(P\)</span> 和 <span class="math inline">\(Q\)</span> 是同概率分布时KL距离为0</p>
<h3 id="极大似然估计">极大似然估计</h3>
<p>极大似然估计，是用来估计一个概率模型的参数的一种方法，它一般求解似然函数</p>
<p><span class="math display">\[L(\theta | x_{1}...x_{m}) = f_{\theta}(x_{1}...x_{m})\]</span></p>
<p>取最大值时的参数 <span class="math inline">\(\widehat{\theta}\)</span></p>
<p><span class="math display">\[\widehat{\theta} = \underset{\theta}{argmax} L(\theta | x_{1}...x_{m})\]</span></p>
<h3 id="隐变量">隐变量</h3>
<p>在统计学中，隐变量或潜变量指的是不可观测的随机变量,隐变量可以通过使用数学模型依据观测得的数据被推断出来。</p>
<p>通俗的说隐变量是存在的但是你无法看到。举个例子吧，分类和聚类看起来是差不多的，都是把一堆相似的东西分到一起，但是分类（显式）提供了类别信息，而聚类没有（显式）提供类别信息，聚类之所以能把一堆相似的东西分到一起可以认为它内部定义了一个“隐藏”的类别信息，可以认为是隐变量</p>
<p>（上述解释系本人捏造的，不一定正确）</p>
<h3 id="jensen-不等式">Jensen 不等式</h3>
<p><img src="/images/posts/em/jensen.jpg"></p>
<p>如果 <span class="math inline">\(f\)</span> 是凸函数(如上图)， <span class="math inline">\(x\)</span> 是随机变量有</p>
<p><span class="math display">\[E(f(x)) \geq f(E(x)) \tag{2}\]</span></p>
<p>凹函数则相反</p>
<p><span class="math display">\[E(f(x)) \leq f(E(x))\]</span></p>
<p><strong>当 <span class="math inline">\(x\)</span> 是常量时上式取等</strong>，即上图<span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>两点重合时取等</p>
<p>Jensen不等式在下述EM算法的推导中很重要</p>
<h4 id="凹凸函数">凹凸函数</h4>
<p>可能受中文<code>凹凸</code>字型的影响会对<code>凹凸</code>函数有歧义，凸函数可理解为<code>下凸</code>，凹函数可理解为<code>上凸</code></p>
<p><img src="/images/posts/em/aotufunc.png"></p>
<h2 id="em算法的推导">EM算法的推导</h2>
<p>EM算法主要分两个求解步骤，称为E步和M步</p>
<h3 id="e步">E步</h3>
<p>假设有训练集</p>
<p><span class="math display">\[{x^{1}, ...., x^{m}}\]</span></p>
<p>包含 <span class="math inline">\(m\)</span> 个独立样本，我们希望从中找到该组数据的模型 <span class="math inline">\(p(x, z)\)</span> 的参数</p>
<p>在这里我们先以<strong>极大似然</strong>的思想去建立目标函数，取对数似然函数</p>
<p><span class="math display">\[L(\theta) = \sum_{i=1}^{m} log\ p(x; \theta) \tag{3}\]</span></p>
<p>我们给 <span class="math inline">\((3)\)</span> 式加入隐变量 <span class="math inline">\(z\)</span> , 对于联合分布 <span class="math inline">\(p(x, z; \theta)\)</span> 有 <span class="math inline">\(\sum_{z}\ p(x, z; \theta) = p(x; \theta)\)</span>, 故有</p>
<p><span class="math display">\[
\begin{align*}
L(\theta) &amp; = \sum_{i=1}^{m} log\ p(x; \theta) \\
&amp; = \sum_{i=1}^{m} log\ \sum_{z} p(x, z; \theta)
\end{align*} \tag{4}
\]</span></p>
<p><span class="math inline">\(z\)</span> 是随机的隐变量，直接找到参数的估计是很困难的，我们要做的是建立 <span class="math inline">\(L(\theta)\)</span> 的下界，然后<strong>求该下界的最大值，重复求解直至收敛到局部最大值</strong></p>
<p>因为假设了样本是独立的，故整体的概率有</p>
<p><span class="math display">\[P = \prod_{i} p(x^{(i)}; \theta) = \prod_{i} \sum_{z^{(i)}}  p(x^{(i)}, z^{(i)}; \theta)\]</span></p>
<p>为了方便推导，一般两边取对数，故有</p>
<p><span class="math display">\[\begin{align*}
log\ P &amp; = \sum_{i} log\ p(x^{(i)}; \theta) \\
&amp; = \sum_{i} log\  \sum_{z^{(i)}} p(x^{(i)}, z^{(i)}; \theta)
\end{align*} \tag{5}\]</span></p>
<p>现在我们假设 <span class="math inline">\(Q_{i}\)</span> 是 <span class="math inline">\(z\)</span> 的某一分布，<span class="math inline">\(Q_{i} \geqslant 0\)</span>， <span class="math inline">\(\sum_{i} Q_{i} = 1\)</span>，此时 <span class="math inline">\((5)\)</span> 有</p>
<p><span class="math display">\[\begin{align*}
log\ P &amp; = \sum_{i} log\ p(x^{(i)}; \theta) \\
&amp; = \sum_{i} log\  \sum_{z^{(i)}} p(x^{(i)}, z^{(i)}; \theta) \\
&amp; = \sum_{i} log\  \sum_{z^{(i)}} Q_{i}(z^{(i)}) \frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})}
\end{align*} \tag{6}\]</span></p>
<p>对于 <span class="math inline">\((6)\)</span> 有</p>
<p><span class="math display">\[\sum_{i} log\  \sum_{z^{(i)}} Q_{i}(z^{(i)}) \frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})} = \sum_{i} log(E_{Q_{i}} (\frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})}) ) \tag{7}\]</span></p>
<p>因为<code>log(x)</code>是凹函数，根据<strong>Jensen不等式</strong>，对于<span class="math inline">\((7)\)</span> 有</p>
<p><span class="math display">\[\begin{align*}
\sum_{i} log(E_{Q_{i}} ( \frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})}) )
\geq \sum_{i} E_{Q_{i}}(log( \frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})}) )
=\sum_{i} \sum_{z^{(i)}} Q_{i}(z^{(i)}) log\frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})} 
\end{align*} \tag{8}\]</span></p>
<p>因此由<span class="math inline">\((8)\)</span>可得</p>
<p><span class="math display">\[\begin{align*}
log\ P &amp; = \sum_{i} log\ p(x^{(i)}; \theta) \\
&amp; = \sum_{i} log\  \sum_{z^{(i)}} p(x^{(i)}, z^{(i)}; \theta) \\
&amp; = \sum_{i} log\  \sum_{z^{(i)}} Q_{i}(z^{(i)}) \frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})} \\
&amp; \geq \sum_{i} \sum_{z^{(i)}} Q_{i}(z^{(i)}) log\frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})} 
\end{align*} \tag{9}\]</span></p>
<p>因为之前已经说了我们要求最大下界，回到Jensen不等式 <span class="math inline">\((2)\)</span> 当x为常量时才能取等号，也就是对于 <span class="math inline">\((8)\)</span> 当</p>
<p><span class="math display">\[\frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})} = c \tag{10}\]</span></p>
<p><span class="math inline">\(c\)</span> 为常数时才能取等，从<strong>KL距离</strong>解释就是当<span class="math inline">\(p\)</span> 和 <span class="math inline">\(Q\)</span> 的KL距离为0时才能取等，也就是说 <span class="math inline">\(p\)</span> 和 <span class="math inline">\(Q\)</span> 是同分布的，而由 <span class="math inline">\((10)\)</span>可知 <strong><span class="math inline">\(p\)</span> 和 <span class="math inline">\(Q\)</span> 是线性关系</strong>，故属于同分布, 对<span class="math inline">\(p\)</span>归一化有</p>
<p><span class="math display">\[\frac{p(x^{(i)}, z^{(i)}; \theta)}{\sum_{z} p(x^{(i)}, z; \theta)} = 1 \tag{11}\]</span></p>
<p>此时刚好满足 <span class="math inline">\(\sum_{z} Q_{i}(z^{(i)}) = 1\)</span>，因此我们可以用 <span class="math inline">\(p\)</span> 来表示 <span class="math inline">\(Q\)</span></p>
<p><span class="math display">\[\begin{align*}
Q_{i}(z^{(i)}) &amp; = \frac{p(x^{(i)}, z^{(i)}; \theta)}{\sum_{z} p(x^{(i)}, z; \theta)} \\
&amp; = \frac{p(x^{(i)}, z^{(i)}; \theta)}{p(x^{(i)}; \theta)} \\
&amp; = p(z^{(i)} | x^{(i)}; \theta)
\end{align*} \tag{12}\]</span></p>
<p>由<span class="math inline">\((12)\)</span>可知，<span class="math inline">\(Q_{i}(z^{(i)})\)</span> 的估计就是给定 <span class="math inline">\(x^{(i)}\)</span> 下 <span class="math inline">\(z^{(i)}\)</span> 发生的条件分布，此时可以使得 <span class="math inline">\((9)\)</span> 式取等</p>
<p>因此<strong>E步可以认为是固定参数 <span class="math inline">\(\theta\)</span> 最大化 <span class="math inline">\(Q_{i}(z^{(i)})\)</span></strong></p>
<h3 id="m步">M步</h3>
<p><strong>M步的思想是固定住 <span class="math inline">\(Q_{i}(z^{(i)})\)</span> 最大化 <span class="math inline">\(\theta\)</span></strong>，即</p>
<p><span class="math display">\[\theta := \underset{\theta}{argmax} \sum_{i} \sum_{z^{(i)}} Q_{i}(z^{(i)}) log\frac{p(x^{(i)}, z^{(i)}; \theta)}{Q_{i}(z^{(i)})} \tag{13}\]</span></p>
<p>至于M步如何求解就是EM算法计算的难点所在，此文不做详细讨论</p>
<h3 id="综述">综述</h3>
<p>由上可知EM算法，就是通过E步和M步来循环更新 <span class="math inline">\(\theta\)</span> 和 <span class="math inline">\(Q\)</span> 使得极值推向设定的收敛值</p>
<h2 id="refrence">Refrence</h2>
<p>[0] https://zh.wikipedia.org/wiki/%E9%9A%90%E5%8F%98%E9%87%8F</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/09/01/SVD的原理及LSA的求解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/01/SVD的原理及LSA的求解/" itemprop="url">SVD的原理及LSA的求解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-01T19:41:55+08:00">
                2018-09-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/01/SVD的原理及LSA的求解/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/09/01/SVD的原理及LSA的求解/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>之前介绍PCA时提到了SVD，本文主要介绍SVD基本概念以及在NLP上的应用。</p>
<h3 id="svd的定义">SVD的定义</h3>
<p>SVD(Singular Value Decomposition)即奇异值分解，奇异值分解区别于特征值分解可用来分解非方阵矩阵问题。假设矩阵 <span class="math inline">\(A \in R^{m\times n}\)</span> 是一个 <span class="math inline">\(m\times n\)</span> 的矩阵，则它的奇异值分解可分解为三个矩阵：</p>
<p><span class="math display">\[A_{m\times n} = U_{m\times m} \Sigma _{m\times n} V^{T}_{n\times n} \tag{1}\]</span></p>
<p>其中 <span class="math inline">\(U\)</span> 和 <span class="math inline">\(V^{T}\)</span> 称为酉矩阵, <span class="math inline">\(\Sigma\)</span> 称为奇异矩阵，它的形式一般为:</p>
<p><span class="math display">\[\Sigma = \begin{bmatrix}
\sigma_{1} &amp; 0 &amp;  ... &amp; 0\\ 
0 &amp; \sigma_{i} &amp; ... &amp; ...\\ 
... &amp; 0 &amp; \sigma_{k} &amp; ...\\
0 &amp; ... &amp; 0 &amp; ...\\
... &amp; 0 &amp; ... &amp; 0 \\  
\end{bmatrix}\]</span></p>
<p><span class="math inline">\(\lambda_{1} ... \lambda _{m}\)</span> 称为奇异值</p>
<p>更一般的我们更希望奇异矩阵是方阵，因此矩阵<span class="math inline">\(A\)</span>可近似分解为</p>
<p><span class="math display">\[A_{m\times n} \approx  U_{m\times k} \Sigma _{k \times k} V^{T}_{k\times n} \tag{2}\]</span></p>
<p>此时奇异矩阵 <span class="math inline">\(\Sigma\)</span> 有</p>
<p><span class="math display">\[\Sigma = \begin{bmatrix}
\sigma_{1} &amp; ... &amp;  0\\ 
0 &amp; \sigma_{i} &amp; ... \\ 
... &amp; 0 &amp; \sigma_{k} \\
\end{bmatrix}\]</span></p>
<p>看起来是不是和特征值分解的对角矩阵很类似，<strong>非方阵的PCA降维原理就是利用这个奇异矩阵进行的</strong></p>
<p>关于PCA请查阅另一篇文章 <a href="https://seanlee97.github.io/2018/03/29/%E4%BB%8E%E7%89%B9%E5%BE%81%E5%80%BC%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E5%8E%BB%E7%90%86%E8%A7%A3PCA/">从特征值特征向量去理解PCA</a></p>
<h3 id="svd的求解">SVD的求解</h3>
<p>SVD的求解还是要回到<strong>方阵</strong>求解上，也就是要回到<strong>特征值特征向量上</strong></p>
<p>可知 <span class="math inline">\(A\)</span> 是 <span class="math inline">\(m\times n\)</span>矩阵，那么 <span class="math inline">\(A^{T} \in R^{n\times m}\)</span>，则有两种情况可构成方阵：</p>
<ul>
<li><span class="math inline">\(AA^{T} \in R^{m\times m}\)</span></li>
<li><span class="math inline">\(A^{T}A \in R^{n\times n}\)</span></li>
</ul>
<p>由 <span class="math inline">\((1)\)</span> 可知, <span class="math inline">\(U \in R^{m\times m}\)</span>，此时我们用 <span class="math inline">\(AA^{T} \in R^{m\times m}\)</span> 来求解，得到特征值特征向量如下：</p>
<p><span class="math display">\[(AA^{T})u_{i} = \lambda_{i} u_{i} \tag{3}\]</span></p>
<p>计算可求得m个特征值和m个特征向量<span class="math inline">\(u\)</span>，这些特征向量称为A的左奇异向量,酉矩阵 <span class="math inline">\(U = [u_{1}...u_{m}]\)</span></p>
<p>同理，<span class="math inline">\(V^{T} \in R^{n\times n}\)</span>，可用 <span class="math inline">\(A^{T}A\)</span> 来求解</p>
<p><span class="math display">\[(A^{T}A) v_{i} = \lambda_{i} v_{i} \tag{4}\]</span></p>
<p>计算可求得n个特征值和n个特征向量<span class="math inline">\(v\)</span>，这些特征向量称为A的右奇异向量,酉矩阵 <span class="math inline">\(V = [v_{1}...v_{n}]\)</span></p>
<p>对于 <span class="math inline">\(\Sigma = [\sigma_{1} ... \sigma_{k}]\)</span> 的求解有</p>
<p><span class="math display">\[\begin{align*}
&amp; A = U\Sigma V^{T} \\\\
&amp; \Rightarrow AV = U\Sigma \\\\
&amp; \Rightarrow Av_{i} = u_{i}\sigma_{i} \\\\
&amp; \Rightarrow \sigma_{i} = A(v_{i} / u_{i})
\end{align*}\]</span></p>
<p>因此奇异值 <span class="math inline">\(\sigma_{i}\)</span> 是由对应的左右奇异向量 <span class="math inline">\(u_{i}\)</span> 和 <span class="math inline">\(v_{i}\)</span> 求得的</p>
<h3 id="lsa的原理与示例">LSA的原理与示例</h3>
<p>NLP中PCA和LSA的原理就是SVD，PCA上面已经做了简要介绍，这里主要说说LSA</p>
<p>LSA(Latent Semantic Analysis) 潜在语义分析的原理就是 SVD，它可以同时完成三个任务</p>
<ul>
<li>近义词分类 (利用的是 <span class="math inline">\(U\)</span> 矩阵)</li>
<li>主题（文档）分类 (利用的是 <span class="math inline">\(V^{T}\)</span> 矩阵)</li>
<li>类词和主题的相关性 (利用的是 <span class="math inline">\(\Sigma\)</span>)</li>
</ul>
<p><img src="/images/posts/svd/lsa.png"></p>
<p>LSA 的核心思想是<strong>将词和文档映射到潜在语义空间</strong>，再比较其相似性。</p>
<p>下面举个实例讲解，如图有</p>
<h4 id="矩阵-x">矩阵 <span class="math inline">\(X\)</span></h4>
<p>矩阵 <span class="math inline">\(X\)</span> 代表词表到文档的矩阵，其中<strong>每行</strong>代表词典中的词，<strong>每一列</strong>代表一篇文档，<span class="math inline">\(X_{ij}=k\)</span> 代表第 <span class="math inline">\(j\)</span> 篇文档中出现了 <span class="math inline">\(k\)</span> 次词 <span class="math inline">\(i\)</span> （也可用TF-IDF代替），可知该矩阵是不包含位置信息的</p>
<p>假设现在有四个文档： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">doc1 = <span class="string">"""计算机科学是系统性研究信息与计算的理论基础以及它们在计算机系统中如何实现与应用的实用技术的学科"""</span></span><br><span class="line">    </span><br><span class="line">doc2 = <span class="string">"""自然语言处理是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言认知则是指让电脑“懂”人类的语言。</span></span><br><span class="line"><span class="string">自然语言生成系统把计算机数据转化为自然语言。自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。"""</span></span><br><span class="line"></span><br><span class="line">doc3 = <span class="string">"""人工智能是计算机科学的一个分支，它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器，</span></span><br><span class="line"><span class="string">该领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等"""</span></span><br><span class="line"></span><br><span class="line">doc4 = <span class="string">"""《瓦尔登湖》是美国作家梭罗独居瓦尔登湖畔的记录，描绘了他两年多时间里的所见、所闻和所思。</span></span><br><span class="line"><span class="string">该书崇尚简朴生活，热爱大自然的风光，内容丰厚，意义深远，语言生动"""</span></span><br></pre></td></tr></table></figure></p>
<p>对每个文档进行分词，去停用词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_vocab</span><span class="params">(self, docs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> docs:</span><br><span class="line">        doc = doc.strip()</span><br><span class="line">        <span class="comment"># 为了简单仅仅保留词的长度大于1的</span></span><br><span class="line">        words = list(filter(<span class="keyword">lambda</span> x: len(x) &gt; <span class="number">1</span>, self.tokenizer(doc))) </span><br><span class="line">        self.docs.append(words)</span><br><span class="line">        self.vocabs.update(words)</span><br><span class="line"></span><br><span class="line">    self.vocabs = list(self.vocabs)</span><br><span class="line">    self.word2idx = dict(zip(self.vocabs, range(len(self.vocabs))))</span><br><span class="line">    </span><br><span class="line">    print(self.vocabs)</span><br></pre></td></tr></table></figure>
<p>输出词典得到： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;方式&apos;, &apos;基础&apos;, &apos;美国作家&apos;, &apos;生动&apos;, &apos;易于&apos;, &apos;人工智能&apos;, &apos;语言&apos;, &apos;计算机系统&apos;, &apos;语言学&apos;, &apos;实质&apos;, &apos;瓦尔登湖&apos;, &apos;生活&apos;, &apos;计算机&apos;, &apos;机器人&apos;, &apos;独居&apos;, &apos;相似&apos;, &apos;人类&apos;, &apos;内容&apos;, &apos;电脑&apos;, &apos;实现&apos;, &apos;所闻&apos;, &apos;计算机程序&apos;, &apos;系统&apos;, &apos;理解&apos;, &apos;理论&apos;, &apos;探讨&apos;, &apos;该书&apos;, &apos;它们&apos;, &apos;数据&apos;, &apos;了解&apos;, &apos;处理&apos;, &apos;企图&apos;, &apos;以及&apos;, &apos;学科&apos;, &apos;生产&apos;, &apos;包括&apos;, &apos;图像识别&apos;, &apos;两年&apos;, &apos;分支&apos;, &apos;一种&apos;, &apos;机器&apos;, &apos;如何&apos;, &apos;风光&apos;, &apos;丰厚&apos;, &apos;描绘&apos;, &apos;认知&apos;, &apos;记录&apos;, &apos;简朴&apos;, &apos;应用&apos;, &apos;智能&apos;, &apos;做出&apos;, &apos;时间&apos;, &apos;自然语言&apos;, &apos;所思&apos;, &apos;崇尚&apos;, &apos;系统性&apos;, &apos;识别&apos;, &apos;梭罗&apos;, &apos;形式&apos;, &apos;大自然&apos;, &apos;深远&apos;, &apos;计算&apos;, &apos;信息&apos;, &apos;意义&apos;, &apos;专家系统&apos;, &apos;生成&apos;, &apos;所见&apos;, &apos;研究&apos;, &apos;一个&apos;, &apos;运用&apos;, &apos;转化&apos;, &apos;领域&apos;, &apos;实用技术&apos;, &apos;计算机科学&apos;, &apos;热爱&apos;, &apos;反应&apos;</span><br></pre></td></tr></table></figure></p>
<p>构造词到文档的矩阵,在这里实现了词袋模型和TF-IDF</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用词袋特征来做权值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_bow_matrix</span><span class="params">(self)</span>:</span></span><br><span class="line">    matrix = np.zeros([len(self.vocabs), len(self.docs)])</span><br><span class="line">    <span class="keyword">for</span> docidx, words <span class="keyword">in</span> enumerate(self.docs):</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            matrix[self.word2idx[word], docidx] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用tf-idf来做权值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_tfidf_matrix</span><span class="params">(self)</span>:</span></span><br><span class="line">    tf = self.build_bow_matrix()</span><br><span class="line">    df = np.ones([len(self.vocabs), <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> docidx, words <span class="keyword">in</span> enumerate(self.docs):</span><br><span class="line">        tf[:, docidx] /= np.max(tf[:, docidx])</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            df[self.word2idx[word], <span class="number">0</span>] += <span class="number">1</span></span><br><span class="line">    idf = np.log(len(self.docs)) - np.log(df)</span><br><span class="line">    <span class="keyword">return</span> tf*idf</span><br></pre></td></tr></table></figure>
<p>得到的矩阵为</p>
<p><strong>词袋模型</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[0. 0. 0. 1.]</span><br><span class="line"> [0. 1. 1. 1.]</span><br><span class="line"> [0. 2. 0. 0.]</span><br><span class="line"> .............</span><br><span class="line"> [0. 0. 0. 1.]</span><br><span class="line"> [0. 0. 1. 0.]</span><br><span class="line"> [1. 0. 0. 0.]]</span><br><span class="line"> </span><br><span class="line"> shape = (vocab_size, doc_size)</span><br></pre></td></tr></table></figure></p>
<p><strong>TF-IDF</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[[ 0.          0.          0.          0.34657359]</span><br><span class="line"> [ 0.          0.          0.          0.        ]</span><br><span class="line"> [ 0.          0.08219488  0.          0.        ]</span><br><span class="line"> .....</span><br><span class="line"> [ 0.          0.          0.          0.34657359]</span><br><span class="line"> [ 0.          0.          0.23104906  0.        ]</span><br><span class="line"> [ 0.69314718  0.          0.          0.        ]]</span><br><span class="line"> </span><br><span class="line"> shape = (vocab_size, doc_size)</span><br></pre></td></tr></table></figure></p>
<h4 id="u-矩阵的应用"><span class="math inline">\(U\)</span> 矩阵的应用</h4>
<p>分解得到的 <span class="math inline">\(U \in R^{m\times m}\)</span> 矩阵<strong>每一行</strong>代表一类近义词,我们一般对每一行的权值进行逆序排序获得top k个权值最大的下标，这些下标对应的词即为近义词</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sim_words</span><span class="params">(self, k=<span class="number">3</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.kernel == <span class="string">'tfidf'</span>:</span><br><span class="line">            matrix = self.build_tfidf_matrix()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            matrix = self.build_bow_matrix()</span><br><span class="line"></span><br><span class="line">        U, S, Vt = np.linalg.svd(matrix)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对权值逆序排序</span></span><br><span class="line">        sort_idx = np.argsort(-U)</span><br><span class="line">        <span class="comment"># 一般不取第一列，第一列的词往往是本身</span></span><br><span class="line">        topk = sort_idx[:, <span class="number">1</span>:k+<span class="number">1</span>] </span><br><span class="line">        print(<span class="string">"word \t similarity"</span>)</span><br><span class="line">        <span class="keyword">for</span> widx, word <span class="keyword">in</span> enumerate(self.vocabs):</span><br><span class="line">            line = word + <span class="string">":\t"</span></span><br><span class="line">            idxs = topk[widx]</span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> idxs:</span><br><span class="line">                line += str(self.vocabs[idx]) + <span class="string">" "</span></span><br><span class="line">            print(line)</span><br></pre></td></tr></table></figure>
<p>得到的结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">计算机系统:	自然语言 领域 如何</span><br><span class="line">数据:	智能 计算机科学 研究</span><br><span class="line">计算机:	智能 计算机科学 研究</span><br><span class="line">语言:	如何 处理 计算</span><br></pre></td></tr></table></figure>
<p>由于只是作为演示用，文档太少，不能得到较好的效果，可用大文本尝试一下</p>
<h4 id="vt-矩阵的应用"><span class="math inline">\(V^{T}\)</span> 矩阵的应用</h4>
<p><span class="math inline">\(V^{T} \in R^{n\times n}\)</span> 矩阵<strong>每一列</strong>代表一个主题，<strong>列中每一行</strong>代表主题相关文档，我们对每一列的权值进行逆序，得到对应下标，这样每一列对应的下标代表同一类别的相关文档下标</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">topic_relate</span><span class="params">(self, k=<span class="number">2</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.kernel == <span class="string">'tfidf'</span>:</span><br><span class="line">            matrix = self.build_tfidf_matrix()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            matrix = self.build_bow_matrix()</span><br><span class="line"></span><br><span class="line">        U, S, Vt = np.linalg.svd(matrix)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 按列逆序排序</span></span><br><span class="line">        sort_idx = np.argsort(-Vt, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 一般不取第一行，第一行是自己本身</span></span><br><span class="line">        topk = sort_idx[<span class="number">1</span>:k+<span class="number">1</span>, :]</span><br><span class="line">        print(topk)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[2 3 0 1]</span><br><span class="line"> [2 0 1 3]]</span><br></pre></td></tr></table></figure>
<h4 id="sigma-矩阵的作用"><span class="math inline">\(\Sigma\)</span> 矩阵的作用</h4>
<p><span class="math inline">\(\Sigma \in R^{m\times n}\)</span> 代表类词和文章类之间的相关性</p>
<p>由此可见LSA可谓一举三得啊！</p>
<h4 id="lsa的缺点及改进">LSA的缺点及改进</h4>
<p>LSA的缺点在于采用暴力SVD矩阵分解，如果维数大了，矩阵大了就难以计算了，加上SVD的分布式计算又是很难实现的，所以在大规模文档中可能不用直接用LSA</p>
<h5 id="plsa">pLSA</h5>
<p>即概率LSA，把LSA变成从概率的角度理解，一般采用的是EM的方式学习</p>
<p>由于pLSA的推导和求解一般涉及到<code>上帝算法</code> — <code>EM</code>（我把它认为是<code>魔鬼算法</code>，因为它原理简单，但是推导要命）在此不做深入讨论</p>
<h3 id="后记">后记</h3>
<p>上述例子均为博主本人生造的，因为网上关于LSA的代码示例很多只做到SVD分解部分，没具体到酉矩阵的应用。</p>
<p>上述实例的完整代码地址: <a href="https://github.com/SeanLee97/nlp_learning/blob/master/lsa/lsa.py" target="_blank" rel="noopener">github/nlp_learning/lsa</a></p>
<h3 id="refrence">Refrence</h3>
<p>[1] https://blog.csdn.net/KIDGIN7439/article/details/69831490</p>
<p>[2] 《数学之美》</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/08/31/余弦定理和文本相似度/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/31/余弦定理和文本相似度/" itemprop="url">余弦定理和文本相似度</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-31T22:02:53+08:00">
                2018-08-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/31/余弦定理和文本相似度/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/08/31/余弦定理和文本相似度/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>数学中常用余弦定理来计算两条边的夹角，NLP中可以用余弦定理来计算文本相似度。</p>
<p>计算两个向量的余弦定理，求得的夹角 <span class="math inline">\(\theta\)</span> 越小，说明两个向量越接近，计算公式如下：</p>
<p><span class="math display">\[\begin{align*}
cos(\theta) &amp;= \frac{\underset{a}{\rightarrow} \cdot \underset{b}{\rightarrow}}{\left \| \underset{a}{\rightarrow} \right \| \left \| \underset{b}{\rightarrow} \right \|} \\
&amp;=  \frac{x_{1} \times x_{2} + y_{1} \times y_{2}}{\sqrt{x_{1}^{2} + y_{1}^{2}} \times \sqrt{x_{2}^{2} + y_{2}^{2}}} \\
&amp; where \underset{a}{\rightarrow} = (x_{1}, y_{1}),\ \underset{b}{\rightarrow} = (x_{2}, y_{2}) 
\end{align*}\]</span></p>
<p>同理如果将两篇文档分别表示成向量利用余弦定理计算不就能得到两篇文档的相关性了吗？ 因此我们第一步要做的就是对文档进行向量化表示，表示方法一般有两种：</p>
<ul>
<li>词袋模型（文本特征为词频）</li>
<li>tf-idf（文本特征为tfidf值)</li>
</ul>
<p>文档中每一个词对应一个维度，因此文档向量是多维的，因此需要对余弦定理泛化，使其能计算多维空间的距离，扩展公式为:</p>
<p><span class="math display">\[\begin{align*}
cos(\theta) &amp;= \frac{\underset{a}{\rightarrow} \cdot \underset{b}{\rightarrow}}{\left \| \underset{a}{\rightarrow} \right \| \left \| \underset{b}{\rightarrow} \right \|} \\
&amp;=  \frac{x_{1} \times y_{2} + x_{2} \times y_{2} + ... + x_{n} \times y_{n}}{\sqrt{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}} \times \sqrt{y_{1}^{2} + y_{2}^{2} + ... + y_{n}^{2}}} \\
&amp; where \underset{a}{\rightarrow} = (x_{1}, x_{1}, ..., x_{n}),\ \underset{b}{\rightarrow} = (y_{2}, y_{2}, ..., y_{n}) 
\end{align*}\]</span></p>
<h4 id="代码实现">代码实现</h4>
<p>如果你熟悉<code>numpy</code>那么上面的计算就是小case了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sim</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, kernel=<span class="string">'tfidf'</span>)</span>:</span></span><br><span class="line">        self.word2idx = &#123;&#125;</span><br><span class="line">        self.kernel = kernel</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(self, sent)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> jieba.lcut(sent)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算词袋向量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc_bow</span><span class="params">(self, docs)</span>:</span></span><br><span class="line">        bow = np.zeros([len(docs), len(self.word2idx)])</span><br><span class="line">        <span class="keyword">for</span> docidx, words <span class="keyword">in</span> enumerate(docs):</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> self.word2idx:</span><br><span class="line">                    bow[docidx, self.word2idx[word]] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> bow</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算tfidf    </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc_tfidf</span><span class="params">(self, docs)</span>:</span></span><br><span class="line">        tf = self.calc_bow(docs)</span><br><span class="line">        df = np.ones([<span class="number">1</span>, len(self.word2idx)])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> docidx, words <span class="keyword">in</span> enumerate(docs):</span><br><span class="line">            tf[docidx] /= np.max(tf[docidx])</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> self.word2idx:</span><br><span class="line">                    df[<span class="number">0</span>, self.word2idx[word]] += <span class="number">1</span></span><br><span class="line">        idf = np.log(len(docs)) - np.log(df)</span><br><span class="line">        tfidf = tf * idf</span><br><span class="line">        <span class="keyword">return</span> tfidf</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算余弦相似度</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cos</span><span class="params">(self, vec1, vec2)</span>:</span></span><br><span class="line">        cos = np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2))</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            cos = np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2))</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            cos = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> cos</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算文本相似度</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">similarity</span><span class="params">(self, doc1, doc2)</span>:</span></span><br><span class="line">        words1 = self.tokenizer(doc1)</span><br><span class="line">        words2 = self.tokenizer(doc2)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 求并集</span></span><br><span class="line">        words = set(words1) | set(words2)</span><br><span class="line">        <span class="comment"># word2idx = &#123;word1:0, word2:1, ...&#125;</span></span><br><span class="line">        self.word2idx = dict(zip(words, range(len(words))))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.kernel == <span class="string">'tfidf'</span>:</span><br><span class="line">            feature = self.calc_tfidf</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            feature = self.calc_bow</span><br><span class="line"></span><br><span class="line">        vec = feature([words1, words2])</span><br><span class="line">        vec1 = vec[<span class="number">0</span>]</span><br><span class="line">        vec2 = vec[<span class="number">1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> self.cos(vec1, vec2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    doc1 = <span class="string">"""计算机科学（英语：computer science，有时缩写为CS）是系统性研究信息与计算的理论基础以及它们在计算机系统中如何实现与应用的实用技术的学科。</span></span><br><span class="line"><span class="string">    [1] [2]它通常被形容为对那些创造、描述以及转换信息的算法处理的系统研究。</span></span><br><span class="line"><span class="string">    计算机科学包含很多分支领域；有些强调特定结果的计算，比如计算机图形学；</span></span><br><span class="line"><span class="string">    而有些是探讨计算问题的性质，比如计算复杂性理论；还有一些领域专注于怎样实现计算，比如编程语言理论是研究描述计算的方法，</span></span><br><span class="line"><span class="string">    而程序设计是应用特定的编程语言解决特定的计算问题，人机交互则是专注于怎样使计算机和计算变得有用、好用，以及随时随地为人所用。"""</span></span><br><span class="line"></span><br><span class="line">    doc2 = <span class="string">"""自然语言处理（英语：natural language processing，缩写作 NLP）是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言认知则是指让电脑“懂”人类的语言。</span></span><br><span class="line"><span class="string">自然语言生成系统把计算机数据转化为自然语言。自然语言理解系统把自然语言转化为计算机程序更易于处理的形式。"""</span></span><br><span class="line">    sim = Sim()</span><br><span class="line">    print(sim.similarity(doc1, doc2))</span><br></pre></td></tr></table></figure>
<h4 id="总结">总结</h4>
<p>NLP中涉及到计算应该下意识的想到将文本转换成空间向量表示，因为向量是能计算的而文本不能直接计算</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/08/25/为朴素贝叶斯加入TF-IDF特征/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/25/为朴素贝叶斯加入TF-IDF特征/" itemprop="url">为朴素贝叶斯加入tf-idf特征</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-25T19:49:59+08:00">
                2018-08-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/25/为朴素贝叶斯加入TF-IDF特征/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/08/25/为朴素贝叶斯加入TF-IDF特征/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>平时都说给分类器加入XX特征效果就好了，于是乎就用工具包懒人式操作几下（无外乎改改参数），很快tf-idf就加好了，但是如果让你完全手写实现那么到底怎么加呢？本文就来结合tf-idf和朴素贝叶斯谈谈加特征的方式。</p>
<h3 id="背景知识">背景知识</h3>
<h4 id="常用的vsm模型">常用的VSM模型</h4>
<p>VSM(vector space model)即向量空间模型，是将文档映射到向量空间上，这样文档就可以计算了（总不可能用一堆文字去计算把）</p>
<ul>
<li>词集模型(set of word): 文档单词构成的集合，词集中的每个单词如果出现就置1没有就置0（也就是没有词频的概念）</li>
<li>词袋模型(bag of word)：文档单词构成的集合，但统计词频，也就是说各个单词的权重不一样的，由词频决定</li>
<li>tf-idf：单词的权重是对应单词的tf-idf值</li>
</ul>
<p>以上的概念很难理解的话看了下面的例子应该就能明白个大概：</p>
<p>假设从语料库中得到一个字典<code>dict</code>: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[I, CS, like, NLP, and]</span><br></pre></td></tr></table></figure></p>
<p>现在有语料库中有两个文档 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">doc1: [I, like, NLP]</span><br><span class="line"></span><br><span class="line">doc2: [I, like, CS, and, like, NLP]</span><br></pre></td></tr></table></figure></p>
<h5 id="词集模型">词集模型</h5>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">doc1: [1, 0, 1, 1, 0]</span><br><span class="line">doc2: [1, 1, 1, 1, 1]</span><br></pre></td></tr></table></figure>
<h5 id="词袋模型">词袋模型</h5>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">doc1: [1, 0, 1, 1, 0]</span><br><span class="line">doc2: [1, 1, 2, 1, 1]  # like出现了两次故词频为2</span><br></pre></td></tr></table></figure>
<h5 id="tf-idf">tf-idf</h5>
<p><span class="math display">\[tf_{term} = \frac{该文章中出现词term的次数}{该文章总词数}\]</span></p>
<p><span class="math display">\[idf_{term} = log(\frac{文档总数}{出现词term的文档数 + 1})\]</span></p>
<p><span class="math display">\[tf-idf = tf \times idf\]</span></p>
<p>根据上述公式得到计算<code>doc1</code>的tf-idf</p>
<p><span class="math display">\[\begin{align*}
tf &amp;= [\frac{1}{3},\ 0,\ \frac{1}{3},\ \frac{1}{3},\ 0] \\
idf &amp;= [log(\frac{2}{2+1}),\ 0,\ log(\frac{2}{2+1}),\ log(\frac{2}{2+1}),\ 0] \\
tf-idf &amp;= [\frac{1}{3} \times log(\frac{2}{2+1}),\ 0,\ \frac{1}{3} \times  log(\frac{2}{2+1}),\ \frac{1}{3} \times log(\frac{2}{2+1}),\ 0]
\end{align*}\]</span></p>
<p>同理可得<code>doc2</code>的tf-idf:</p>
<p><span class="math display">\[\begin{align*}
tf &amp;= [\frac{1}{6},\ \frac{1}{6},\ \frac{2}{6},\ \frac{1}{6},\ \frac{1}{6}] \\
idf &amp;= [log(\frac{2}{2+1}),\ log(\frac{2}{1+1}),\ log(\frac{2}{2+1}),\ log(\frac{2}{2+1}),\ log(\frac{2}{1+1})] \\
tf-idf &amp;= [\frac{1}{6} \times log(\frac{2}{2+1}),\ \frac{1}{6} \times \frac{2}{1+1},\ \frac{2}{6} \times  log(\frac{2}{2+1}),\ \frac{1}{6} \times log(\frac{2}{2+1}),\ \frac{1}{6} \times log(\frac{2}{1+1})]
\end{align*}\]</span></p>
<h3 id="朴素贝叶斯nb">朴素贝叶斯(NB)</h3>
<p><code>NB</code>属于生成模型，生成模型学习的是联合概率<code>p(x, y)</code>, 它是利用先验概率<code>p(y)</code>和<code>p(x|y)</code>来训练的，最后预测时使用贝叶斯定理来预测:</p>
<p><span class="math display">\[p(y|x_{1}...x_{m}) = \frac{p(y)p(x_{1}...x_{m}|y)}{\sum_{y{}&#39; \epsilon \gamma} p(y{}&#39;)p(x_{1}...p_{m}|y{}&#39;)}\]</span></p>
<p>为了简化问题，<code>NB</code>做了一个朴素的假设，假设输入之间是独立的，因此可得</p>
<p><span class="math display">\[p(y|x_{1}...x_{m}) = \frac{p(y)\prod_{i}^{m} p(x_{i}|y)}{\sum_{y{}&#39; \epsilon \gamma} p(y{}&#39;)p(x_{1}...p_{m}|y{}&#39;)}\]</span></p>
<p>朴素贝叶斯分类器的求解目标为:</p>
<p><span class="math display">\[\underset{y}{argmax} \sum _{y \epsilon \gamma}p(y|x_{1}...x_{m})\]</span></p>
<p>最终求得的<code>y</code>即为分类结果</p>
<h3 id="代码部分">代码部分</h3>
<p>有前文可知tf-idf是用一个向量来表示的，为了方便添加特征我们只能用BOW的方式去构建输入，放了方便向量运算我们使用<code>numpy</code>来构建</p>
<p>为了对比，我们实现两种特征<code>词袋</code>和<code>tf-idf</code>作为模型的输入</p>
<h4 id="语料处理部分">语料处理部分</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Corpus</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        self.tags = defaultdict(int)</span><br><span class="line">        self.vocabs = set()</span><br><span class="line">        self.docs = []</span><br><span class="line">        </span><br><span class="line">        self.build_vocab(data)</span><br><span class="line">        self.v_l = len(self.vocabs) <span class="comment"># 字典的大小</span></span><br><span class="line">        self.d_l = len(self.docs)   <span class="comment"># 文档数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 分词器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(self, sent)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> jieba.lcut(sent)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建字典，获取分类标记集</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_vocab</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> (tag, doc) <span class="keyword">in</span> data:</span><br><span class="line">            words = self.tokenizer(doc)</span><br><span class="line">            self.vocabs.update(words)</span><br><span class="line">            self.tags[tag] += <span class="number">1</span></span><br><span class="line">            self.docs.append((tag, words))</span><br><span class="line">        self.vocabs = list(self.vocabs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算词袋模型</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc_bow</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># shape为 [d_l, v_l]，每一行存放文档的词袋向量</span></span><br><span class="line">        self.bow = np.zeros([self.d_l, self.v_l])</span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(self.d_l):</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> self.docs[idx][<span class="number">1</span>]:</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> self.vocabs:</span><br><span class="line">                    self.bow[idx, self.vocabs.index(word)] += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算tf-idf</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">calc_tfidf</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 先计算bow，再用bow来计算tf</span></span><br><span class="line">        self.calc_bow()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化tf、df、idf</span></span><br><span class="line">        self.tf = np.zeros([self.d_l, self.v_l])</span><br><span class="line">        self.idf = np.ones([<span class="number">1</span>, self.v_l])</span><br><span class="line">        self.tf_idf = np.ones([self.d_l, self.v_l])</span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(self.d_l):</span><br><span class="line">            self.tf[idx] = self.bow[idx] /np.sum(self.bow[idx])</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> self.vocabs:</span><br><span class="line">                <span class="keyword">if</span> word <span class="keyword">in</span> self.vocabs:</span><br><span class="line">                    self.idf[<span class="number">0</span>, self.vocabs.index(word)] += <span class="number">1</span></span><br><span class="line">        self.idf = np.log(float(self.d_l) / self.idf)</span><br><span class="line">        self.tfidf = self.tf * self.idf</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 计算输入的bow向量，words代表输入序列（已分词）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_idx</span><span class="params">(self, words)</span>:</span></span><br><span class="line">        bow = np.zeros([<span class="number">1</span>, self.v_l])</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">in</span> self.vocabs:</span><br><span class="line">                bow[<span class="number">0</span>, self.vocabs.index(word)] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> bow</span><br></pre></td></tr></table></figure>
<p>上述代码主要计算了<code>tf-idf</code>，词袋模型<code>bow</code></p>
<h4 id="实现nb">实现NB</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NB继承了语料类Corpus</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NBayes</span><span class="params">(Corpus)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, kernel=<span class="string">"tfidf"</span>)</span>:</span></span><br><span class="line">        super(NBayes, self).__init__(data)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># kernel 代表使用哪种特征，默认是tfidf，赋其他值代表使用bow</span></span><br><span class="line">        self.kernel = kernel</span><br><span class="line">        self.y_prob = &#123;&#125; <span class="comment"># p(y_i)</span></span><br><span class="line">        self.c_prob = <span class="keyword">None</span> <span class="comment"># p(x|y_i) , 计算条件概率</span></span><br><span class="line">        self.feature = <span class="keyword">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 训练，主要计算 p(y_i)和条件概率 p(x|y_i)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.kernel == <span class="string">"tfidf"</span>:</span><br><span class="line">            self.calc_tfidf()</span><br><span class="line">            self.feature = self.tfidf</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.calc_bow()</span><br><span class="line">            self.feature = self.bow</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># 采用极大似然估计计算p(y)</span></span><br><span class="line">        <span class="keyword">for</span> tag <span class="keyword">in</span> self.tags:</span><br><span class="line">            self.y_prob[tag] = float(self.tags[tag])/ self.d_l</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算条件概率 p(x|y_i)</span></span><br><span class="line">        self.c_prob = np.zeros([len(self.tags), self.v_l])</span><br><span class="line">        Z = np.zeros([len(self.tags), <span class="number">1</span>]) <span class="comment"># 归一化参数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> range(self.d_l):</span><br><span class="line">            <span class="comment"># 获得类别标签id</span></span><br><span class="line">            tid = list(self.tags.keys()).index(self.docs[idx][<span class="number">0</span>])</span><br><span class="line">            self.c_prob[tid] += self.feature[idx]</span><br><span class="line">            Z[tid] = np.sum(self.c_prob[tid])</span><br><span class="line"></span><br><span class="line">        self.c_prob /= Z  <span class="comment"># 归一化</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 解码部分，返回使得概率值最大的类别y</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, inp)</span>:</span></span><br><span class="line">        words = self.tokenizer(inp)</span><br><span class="line">        idx = self.get_idx(words)</span><br><span class="line"></span><br><span class="line">        tag, score = <span class="keyword">None</span>, <span class="number">-1</span></span><br><span class="line">        <span class="keyword">for</span> (p_c, y) <span class="keyword">in</span> zip(self.c_prob, self.y_prob):</span><br><span class="line">            tmp = np.sum(idx * p_c * self.y_prob[y])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> tmp &gt; score:</span><br><span class="line">                tag = y</span><br><span class="line">                score = tmp</span><br><span class="line">        <span class="keyword">return</span> tag, <span class="number">1.0</span> - score</span><br></pre></td></tr></table></figure>
<h4 id="测试">测试</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">trainSet = [(<span class="string">"pos"</span>, <span class="string">"good job !"</span>),</span><br><span class="line">                (<span class="string">"pos"</span>, <span class="string">"表现不错哦"</span>), </span><br><span class="line">                (<span class="string">"pos"</span>, <span class="string">"厉害咯"</span>), </span><br><span class="line">                (<span class="string">"pos"</span>, <span class="string">"做的很好啊"</span>), </span><br><span class="line">                (<span class="string">"pos"</span>, <span class="string">"做得不错继续努力"</span>),</span><br><span class="line">                (<span class="string">"pos"</span>, <span class="string">"不错！点赞"</span>),</span><br><span class="line">                (<span class="string">"neg"</span>, <span class="string">"太差了"</span>), </span><br><span class="line">                (<span class="string">"neg"</span>, <span class="string">"太糟糕了"</span>), </span><br><span class="line">                (<span class="string">"neg"</span>, <span class="string">"你做的一点都不好"</span>), </span><br><span class="line">                (<span class="string">"neg"</span>, <span class="string">"不行，重做"</span>),</span><br><span class="line">                (<span class="string">"neg"</span>, <span class="string">"so bad"</span>),</span><br><span class="line">                (<span class="string">"non"</span>, <span class="string">"一般般吧，还过的去"</span>), </span><br><span class="line">                (<span class="string">"non"</span>, <span class="string">"不算太好，也不算太差"</span>), </span><br><span class="line">                (<span class="string">"non"</span>, <span class="string">"继续努力吧"</span>)</span><br><span class="line">               ]</span><br><span class="line">               </span><br><span class="line">    nb = NBayes(trainSet)</span><br><span class="line">    nb.train()</span><br><span class="line">    print(nb.predict(<span class="string">"不错哦"</span>)) <span class="comment"># ('pos', 0.9142857142857143)</span></span><br></pre></td></tr></table></figure>
<h3 id="扩展">扩展</h3>
<p>神经网络分类器模型一般如何添加特征呢？笔者一般使用两种方式：</p>
<ul>
<li>在词嵌入层 (Word Embedding)进行拼接</li>
<li>通过Attention计算引入</li>
</ul>
<p>本文完整代码放在 <a href="https://github.com/SeanLee97/nlp_learning/tree/master/nbayes" target="_blank" rel="noopener">github/nlp_learning/nbayes</a> 欢迎查阅</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/08/23/谈谈python中的元类以及实现一个简单的ORM框架/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/23/谈谈python中的元类以及实现一个简单的ORM框架/" itemprop="url">谈谈python中的元类以及实现一个简单的ORM框架</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-23T00:15:27+08:00">
                2018-08-23
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/23/谈谈python中的元类以及实现一个简单的ORM框架/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/08/23/谈谈python中的元类以及实现一个简单的ORM框架/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>大家都说python中的元类(metaclass)在真实场景中99%的几率都用不到，但是最大熵理论告诉我们，面对未知风险，我们不能报侥幸心理，我们应该平权看待所有潜在风险，不应该放过任何一处潜在风险。</p>
<p>So，本文主要讲讲python的元类，为了不枯燥无味，本文以一个初级ORM框架例子来讲解。</p>
<h3 id="什么是orm">什么是ORM</h3>
<p>Object Relational Mapping 即 对象-关系映射，在关系型数据库中就是把关系数据库的一行映射为一个对象，即一个类对应一个表，这样，你就不需要每次都用pymysql去封装每条sql了，把重复的操作交给<code>ORM</code>，如<code>sqlalchemy</code>就是一个 <code>ORM</code>框架</p>
<p>可能这个解释有点牵强，在此举个例子把，比如说你要向一个数据表<code>user</code>插入数据，你可能会写: <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">user</span>(<span class="keyword">name</span>, age) <span class="keyword">values</span>(<span class="string">'seanlee'</span>, <span class="number">21</span>)</span><br></pre></td></tr></table></figure></p>
<p>当插入数据到其他表时比如说<code>course</code>时，你又要: <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course(<span class="keyword">name</span>, teacher) <span class="keyword">values</span>(<span class="string">'computer sicence'</span>, <span class="string">'Mr.Gates'</span>)</span><br></pre></td></tr></table></figure></p>
<p>这时你发现每次插入数据都要自己写完所有语句，且要处理完整个逻辑过程。这真的很累，于是乎，如果有一个框架能把这些复杂的工作给做了，使用者只需封装好模型类即可自动完成复杂的流程。 你的想法可能是这样的： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span><span class="params">(ORM)</span>:</span></span><br><span class="line">    <span class="comment"># 定义数据表的字段</span></span><br><span class="line">    name = CharField()</span><br><span class="line">    age = IntField()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    user = User()</span><br><span class="line">    user.name = <span class="string">"seanlee"</span></span><br><span class="line">    user.age = <span class="number">21</span></span><br><span class="line">    user.save()   <span class="comment"># 调用save函数框架自动将数据插入到数据库中</span></span><br></pre></td></tr></table></figure></p>
<p>好了，上面就是<code>ORM</code>的大致思路了，本文要实现的目标就是完成上面代码的内部逻辑。</p>
<h3 id="什么是元类">什么是元类</h3>
<p>元类<code>metaclass</code>是类的类，简单的说就是元类是用来生产类的，可以说元类是<strong>最上层</strong>的类。可能还是很难理解，举几个例子把</p>
<h4 id="object类">1. object类</h4>
<p>平时大家定义类时可能会继承<code>object</code>类，大家下意识的认为<code>object</code>就是最上层的类了，其实不是，我们输出<code>object</code>的类型看看 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(type(object)) <span class="comment"># &lt;type 'type'&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>object</code>类的类型是<code>type</code>类型，那么<code>type</code>类型又是什么呢？<code>type</code>类型就是指<code>type</code>类，大家都以为<code>type()</code>是一个函数，其实它是一个<strong>类</strong>，当只传一个参数时它会返回参数的类型。</p>
<p><strong>其实<code>type</code>就是python的元类</strong>，看下面程序： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(type(type))  <span class="comment"># &lt;type 'type'&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到<code>type</code>的类型就是<code>type</code></p>
<h4 id="基本数据类型">2. 基本数据类型</h4>
<p>python中的基本数据类型也可看为对象，它们的直属类型的类就是 <code>type</code>，看下面例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(type(type(<span class="number">97</span>)))   <span class="comment"># 整型</span></span><br><span class="line">print(type(type(<span class="number">97.0</span>))) <span class="comment"># 浮点</span></span><br><span class="line">print(type(type(<span class="string">"seanlee"</span>))) <span class="comment"># 字符串</span></span><br><span class="line">print(type(type((<span class="number">9</span>, <span class="number">7</span>))))    <span class="comment"># 元组</span></span><br><span class="line">print(type(type([<span class="number">9</span>, <span class="number">7</span>])))    <span class="comment"># 列表</span></span><br><span class="line">print(type(type(&#123;<span class="string">"key"</span>: <span class="string">"val"</span>&#125;))) <span class="comment"># 字典</span></span><br></pre></td></tr></table></figure>
<p>输出结果为： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;type &apos;type&apos;&gt;</span><br><span class="line">&lt;type &apos;type&apos;&gt;</span><br><span class="line">&lt;type &apos;type&apos;&gt;</span><br><span class="line">&lt;type &apos;type&apos;&gt;</span><br><span class="line">&lt;type &apos;type&apos;&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="元类的作用">元类的作用</h4>
<p>掌握了元类，你就是“类”的老大了，你可以按照你的方式去修改类，就好比你得到了Linux的root帐号，你可以为所欲为了。也好比你是微信群的群主，拥有直接拉人入群、踢人出群的权力，python中的元类也类似可以用于对类属性的增删操作。</p>
<p>好啦，到这里你应该理解元类的概念了</p>
<h3 id="type类">type类</h3>
<p>从此刻起一定要更正观念<code>type</code>是一个类，它有三个参数： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">type(what [, bases, dict])</span><br></pre></td></tr></table></figure></p>
<p>可见后两个参数是可选的，各参数的意义：</p>
<ul>
<li>what: 输入的实例</li>
<li>bases：类的基类，传入的是元组</li>
<li>dict：类的属性、方法</li>
</ul>
<p>举几个例子说明，type的用法</p>
<h4 id="直接生产类">直接生产类</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">User = type(<span class="string">'User'</span>, (object, ), &#123;<span class="string">'name'</span>: <span class="string">'seanlee'</span>, <span class="string">'age'</span>: <span class="number">21</span>&#125;)</span><br><span class="line">user = User()</span><br><span class="line">print(user.name)  <span class="comment"># seanlee</span></span><br><span class="line">print(user.age)   <span class="comment"># 21</span></span><br></pre></td></tr></table></figure>
<h4 id="修改类属性">修改类属性</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span><span class="params">(object)</span>:</span></span><br><span class="line">    name = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">user = User()</span><br><span class="line">print(user.name) <span class="comment"># None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_name</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self.name</span><br><span class="line"></span><br><span class="line">User = type(<span class="string">'User'</span>, (object, ), &#123;<span class="string">'name'</span>:<span class="string">'seanlee'</span>, <span class="string">'get_name'</span>: get_name&#125;)</span><br><span class="line">user = User()</span><br><span class="line">print(user.name)  <span class="comment"># seanlee</span></span><br><span class="line">print(user.get_name())   <span class="comment"># seanlee</span></span><br></pre></td></tr></table></figure>
<h3 id="python中类的创建">python中类的创建</h3>
<ul>
<li>如果类中没有定义metaclass，那么直接用type创建</li>
<li>如果用户定义了metaclass那么以metaclass的方式创建</li>
</ul>
<h3 id="自定义元类的创建">自定义元类的创建</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Metaclass</span><span class="params">(type)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span><span class="params">(cls, name, bases, attrs, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment"># do something here.</span></span><br><span class="line">        print(<span class="string">"call Metaclass"</span>)</span><br><span class="line">        <span class="keyword">return</span> super(Metaclass, cls).__new__(cls, name, bases, attrs, **kwargs)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span><span class="params">(metaclass=Metaclass)</span>:</span></span><br><span class="line">    <span class="comment"># __metaclass__ = Metaclass # python2支持的方式</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"call User"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    User()</span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">call Metaclass</span><br><span class="line">call User</span><br></pre></td></tr></table></figure></p>
<h3 id="开始打造orm">开始打造ORM</h3>
<h4 id="使用描述器定义字段属性">1. 使用描述器定义字段属性</h4>
<p>如果不了解描述器，请阅读<a href="https://seanlee97.github.io/2018/08/21/python%E4%B8%AD%E7%9A%84%E6%8F%8F%E8%BF%B0%E5%99%A8/">python中的描述器</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 定义字段属性的基类Field，它的用处主要用于识别类属性中属于字段的那些属性</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Field</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 整型字段属性</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IntField</span><span class="params">(Field)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, db_column=<span class="string">""</span>)</span>:</span></span><br><span class="line">        self._value = <span class="keyword">None</span> <span class="comment"># 表的数据</span></span><br><span class="line">        self.db_column = db_column</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(value, int):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"input should be a Integer"</span>)</span><br><span class="line">        self._value = value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._value</span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符型字段属性</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>  <span class="title">CharField</span><span class="params">(Field)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, db_column=<span class="string">""</span>)</span>:</span></span><br><span class="line">        self._value  = <span class="keyword">None</span> </span><br><span class="line">        self.db_column = db_column</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._value</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(value, str):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"input should be a String"</span>)</span><br><span class="line">        self._value = value</span><br></pre></td></tr></table></figure>
<h4 id="定义元类">2. 定义元类</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MetaModel</span><span class="params">(type)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span><span class="params">(cls, name, bases, attrs, **kwargs)</span>:</span></span><br><span class="line">        fields = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> key, val <span class="keyword">in</span> attrs.items():</span><br><span class="line">            <span class="comment"># 把attrs中与数据库表字段有关的列提取出来</span></span><br><span class="line">            <span class="keyword">if</span> isinstance(val, Field):</span><br><span class="line">                fields[key] = val   <span class="comment"># value 直接走描述器__get__()</span></span><br><span class="line"></span><br><span class="line">        _meta = &#123;&#125;</span><br><span class="line">        db_table = name.lower()  <span class="comment"># 数据表名称默认取小写类名称</span></span><br><span class="line">        _meta[<span class="string">'db_table'</span>] = db_table</span><br><span class="line">        attrs[<span class="string">'_meta'</span>] = _meta</span><br><span class="line">        attrs[<span class="string">'_fields'</span>] = fields</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 以上过程相当于对类进行了修改</span></span><br><span class="line">        <span class="keyword">return</span> super(MetaModel, cls).__new__(cls, name, bases, attrs, **kwargs)</span><br></pre></td></tr></table></figure>
<h4 id="定义模型基类">3. 定义模型基类</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span><span class="params">(metaclass=MetaModel)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> key, val <span class="keyword">in</span> kwargs.items():</span><br><span class="line">            setattr(self, key, val)</span><br><span class="line">        <span class="keyword">return</span> super(Model, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(self)</span>:</span></span><br><span class="line">        fields = []</span><br><span class="line">        values = []</span><br><span class="line">        <span class="keyword">for</span> key, val <span class="keyword">in</span> self._fields.items():</span><br><span class="line">            db_column = val.db_column</span><br><span class="line">            <span class="keyword">if</span> db_column <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                db_column = key.lower()</span><br><span class="line">            fields.append(db_column)</span><br><span class="line">            value = getattr(self, key) <span class="comment"># 字段的值</span></span><br><span class="line">            values.append(str(value))</span><br><span class="line">        sql = <span class="string">"insert &#123;name&#125; (&#123;field&#125;) values (&#123;value&#125;)"</span>.format(name=self._meta[<span class="string">'db_table'</span>],</span><br><span class="line">                                                             field=<span class="string">','</span>.join(fields),</span><br><span class="line">                                                             value=<span class="string">','</span>.join(values))</span><br><span class="line">        <span class="keyword">return</span> sql</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">select</span><span class="params">(self)</span>:</span></span><br><span class="line">        fields = []</span><br><span class="line">        where = []</span><br><span class="line">        <span class="keyword">for</span> key, val <span class="keyword">in</span> self._fields.items():</span><br><span class="line">            db_column = val.db_column</span><br><span class="line">            <span class="keyword">if</span> db_column <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                db_column = key.lower()</span><br><span class="line">            fields.append(db_column)</span><br><span class="line">            v = getattr(self, key, <span class="keyword">None</span>)</span><br><span class="line">            <span class="keyword">if</span> v <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                where.append([key, str(v)])</span><br><span class="line"></span><br><span class="line">        sql = <span class="string">'select &#123;fields&#125; from &#123;name&#125; where &#123;where&#125;'</span>.format(name=self._meta[<span class="string">'db_table'</span>],</span><br><span class="line">                                                                 fields=<span class="string">','</span>.join(fields),</span><br><span class="line">                                                                 where=<span class="string">' and '</span>.join([<span class="string">'='</span>.join(x) <span class="keyword">for</span> x <span class="keyword">in</span> where]),</span><br><span class="line">                                                                 )</span><br><span class="line">        <span class="keyword">return</span> sql</span><br></pre></td></tr></table></figure>
<p>上述三步就完成了简单orm的搭建了，为了简单没封装真实的数据库操作，仅返回SQL语句而已。</p>
<h4 id="操作实例">4. 操作实例</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span><span class="params">(Model)</span>:</span></span><br><span class="line">    name = CharField(db_column=<span class="string">"name"</span>, max_length=<span class="number">10</span>)</span><br><span class="line">    age = IntField(db_column=<span class="string">"age"</span>, min=<span class="number">0</span>, max=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Meta</span>:</span> <span class="comment"># 使用内部类来定义数据表的其他属性</span></span><br><span class="line">        db_table = <span class="string">"db_user"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    user = User(name=<span class="string">'seanlee'</span>, age=<span class="number">15</span>)</span><br><span class="line">    user.name = <span class="string">'sean'</span></span><br><span class="line">    print(user.save())</span><br><span class="line">    print(user.select())</span><br></pre></td></tr></table></figure>
<p>输出 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert user (name,age) values (sean,15)</span><br><span class="line">select name,age from user where name=sean and age=15</span><br></pre></td></tr></table></figure></p>
<p>上述代码放在了Github中，欢迎查阅<a href="https://github.com/SeanLee97/python_intermediate/blob/master/metaclass/orm.py" target="_blank" rel="noopener">python_intermediate / metaclass / orm</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/08/21/python中的描述器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/21/python中的描述器/" itemprop="url">python中的描述器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-21T20:32:24+08:00">
                2018-08-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/21/python中的描述器/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/08/21/python中的描述器/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>描述器和装饰器是两个不同的东西，描述器是类中封装了__set__(), __get__(), __delete__()等魔术方法。</p>
<p>python中的属性、实例方法、静态方法、类方法、<code>super</code>都是基于描述器实现的</p>
<p>python中默认的对属性的访问控制是从对象字典__dict__中进行封装的，以obj.x举例，它的默认查找顺序是</p>
<ul>
<li>先查找实例的__dict__即obj.__dict__[‘x’]</li>
<li>若查找不到，再查找type(obj).__dict__[‘x’]</li>
<li>若查找不到，最后查找type(obj)的父类(不包括__metaclass__)</li>
</ul>
<p>但是当定义了描述器时，python就会调用描述器的方法来重写默认的控制行为</p>
<h3 id="描述器的分类">描述器的分类</h3>
<ul>
<li>资料描述器：同时定义了__set__()，和__get__()方法</li>
<li>非资料描述器：仅定义了__get__()方法</li>
</ul>
<p>它们的区别在于：主要区别在于实例字典的优先级上。如果访问的属性在字典实例中且是资料描述器那么以资料描述器的为主，否则若是非资料描述器则以实例字典的为主。</p>
<h3 id="与__setattr____getattr____getattribute__的关系">与__setattr__()，__getattr__()，__getattribute__()的关系</h3>
<ul>
<li>__setattr__()的优先级高于描述器的__set__()的方法</li>
<li>如果属性已经定义了那么不会再执行__getattr__()了，而是直接通过访问实例字典返回结果，但如果存在描述器则走描述器的__get__()方法，__getattr__()只在访问未定义的属性时被触发</li>
<li>__getattribute__()：在调用类方法，字典__dict__属性时会通过访问此魔术方法实现，如果同一个类中也封装了__setattr__()且操作了self.__dict__那么将会陷入无限循环</li>
<li>描述器的调用也是因为__getattribute__()，当重写了__getattribute__()时会阻止描述器的调用</li>
</ul>
<h3 id="实例">实例</h3>
<h4 id="描述器的基本使用">描述器的基本使用</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Meter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a meter.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        self.value = float(value)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.value</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        self.value = float(value)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foot</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a foot.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> instance.meter * <span class="number">3.2808</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        instance.meter = float(value) / <span class="number">3.2808</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Distance</span><span class="params">(object)</span>:</span></span><br><span class="line">    meter = Meter()</span><br><span class="line">    foot = Foot()</span><br><span class="line"></span><br><span class="line">d = Distance()</span><br><span class="line">print(d.meter, d.foot)  <span class="comment"># 0.0, 0.0</span></span><br><span class="line">d.meter = <span class="number">1</span></span><br><span class="line">print(d.meter, d.foot)  <span class="comment"># 1.0 3.2808</span></span><br><span class="line">d.meter = <span class="number">2</span></span><br><span class="line">print(d.meter, d.foot)  <span class="comment"># 2.0 6.5616</span></span><br></pre></td></tr></table></figure>
<h4 id="存在__setattr__时的资料描述器">存在__setattr__()时的资料描述器</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Meter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a meter.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        self.value = float(value)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.value</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        self.value = float(value)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foot</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a foot.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> instance.meter * <span class="number">3.2808</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        instance.meter = float(value) / <span class="number">3.2808</span></span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Distance</span><span class="params">(object)</span>:</span></span><br><span class="line">    meter = Meter()</span><br><span class="line">    foot = Foot()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setattr__</span><span class="params">(self, name, value)</span>:</span></span><br><span class="line">        print(<span class="string">"__setattr__"</span>)</span><br><span class="line">        self.__dict__[name] = value</span><br><span class="line"></span><br><span class="line">d = Distance()</span><br><span class="line">print(d.meter, d.foot) </span><br><span class="line">d.meter = <span class="number">1</span></span><br><span class="line">print(d.meter, d.foot) </span><br><span class="line">d.meter = <span class="number">2</span></span><br><span class="line">print(d.meter, d.foot)</span><br></pre></td></tr></table></figure>
<p>输出： <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0.0 0.0</span><br><span class="line">__setattr__</span><br><span class="line">0.0 0.0</span><br><span class="line">__setattr__</span><br><span class="line">0.0 0.0</span><br></pre></td></tr></table></figure></p>
<p>由于资料描述器的__get__()优先级高于实例字典，故会一致访问资料描述器的值，__setattr__()的优先级高于描述器的__set__()所以更新的是实例字典的值</p>
<h4 id="存在__setattr__时的非资料描述器">存在__setattr__()时的非资料描述器</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Meter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a meter.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        self.value = float(value)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.value</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foot</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a foot.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> instance.meter * <span class="number">3.2808</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Distance</span><span class="params">(object)</span>:</span></span><br><span class="line">    meter = Meter()</span><br><span class="line">    foot = Foot()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__setattr__</span><span class="params">(self, name, value)</span>:</span></span><br><span class="line">        print(<span class="string">"__setattr__"</span>)</span><br><span class="line">        self.__dict__[name] = value</span><br><span class="line"></span><br><span class="line">d = Distance()</span><br><span class="line">print(d.meter, d.foot)</span><br><span class="line">d.meter = <span class="number">1</span></span><br><span class="line">print(d.meter, d.foot)</span><br><span class="line">d.meter = <span class="number">2</span></span><br><span class="line">print(d.meter, d.foot)</span><br></pre></td></tr></table></figure>
<p>输出 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0.0 0.0</span><br><span class="line">__setattr__</span><br><span class="line">1 3.2808</span><br><span class="line">__setattr__</span><br><span class="line">2 6.5616</span><br></pre></td></tr></table></figure></p>
<p>实例字典的优先级高于非资料描述器</p>
<h2 id="refrence">Refrence</h2>
<p>[1] https://pyzh.readthedocs.io/en/latest/Descriptor-HOW-TO-Guide.html#id11</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/08/20/谈谈序列标注三大模型HMM、MEMM、CRF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/20/谈谈序列标注三大模型HMM、MEMM、CRF/" itemprop="url">谈谈序列标注三大模型HMM、MEMM、CRF</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-20T21:19:05+08:00">
                2018-08-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/20/谈谈序列标注三大模型HMM、MEMM、CRF/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/08/20/谈谈序列标注三大模型HMM、MEMM、CRF/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>很久之前曾经接触过CRF，但是觉得这东西太晦涩难懂了，看了很多科普博客但很多都是从概率图的层面上解释的，虽然图形能让你很快了解个大概，但是有些地方疑惑时是很难从图形中得到答案的，所以我更喜欢从公式出发。最近重拾CRF，顺便也回顾了<code>HMM</code> <code>MEMM</code>，这几个模型主要用在了序列标注上，故在此形成一个小型知识体系便于以后复习。</p>
<h2 id="前情知识">前情知识</h2>
<h3 id="生成模型-判别模型">生成模型 &amp; 判别模型</h3>
<h4 id="生成模型">生成模型</h4>
<p>生成模型学习的是联合概率<span class="math inline">\(p(x, y)= p(x|y) p(y)\)</span>，然后利用贝叶斯定理来求解后验概率<span class="math inline">\(p(y|x)\)</span> <span class="math display">\[p(y|x) = \frac{p(x|y)p(y)}{\sum_{y{}&#39; \epsilon \gamma} p(x|y{}&#39;)p(y{}&#39;)}\]</span></p>
<p>常见的生成模型有：朴素贝叶斯（NB），HMM</p>
<h4 id="判别式模型">判别式模型</h4>
<p>直接学习<span class="math inline">\(p(y|x)\)</span>，判别式模型根据所提供的feature直接学习一个分类边界</p>
<p>常见的判别式模型：神经网络，SVM，CRF</p>
<div style="text-align: center">
<img src="/images/posts/crf/models.png" alt="">
</div>
<h3 id="对数线性模型log-linear-model">对数线性模型（log-linear model）</h3>
<p>对于有一系列输入数据 <span class="math inline">\(\chi\)</span> ，和一系列标签数据 <span class="math inline">\(\gamma\)</span> ，如何通过这些标注数据来求解 <span class="math inline">\(p(y|x)\)</span> 呢？ 一般可以用对数线性模型来求解，也就是判别模型一般可以通过对数线性模型来建模，常见的最大熵模型、softmax、<strong>MEMM、CRF都使用了对数线性模型</strong>。</p>
<p>对数线性模型形如： <span class="math display">\[p(y|x;w) = \frac{exp(w\cdot f(x, y))}{\sum _{y{}&#39;\epsilon \gamma} exp(w\cdot f(x, y{}&#39;))}\]</span></p>
<p>其中有：</p>
<ul>
<li>输入集合 <span class="math inline">\(\chi\)</span></li>
<li>标签集合 <span class="math inline">\(\gamma\)</span></li>
<li><span class="math inline">\(w \epsilon \mathbb{R}^{d}\)</span> 是模型的参数</li>
<li>$x $, <span class="math inline">\(y \epsilon \gamma\)</span></li>
<li>特征函数 <span class="math inline">\(f:\chi \times \gamma \rightarrow \mathbb{R}^{d}\)</span></li>
<li><span class="math inline">\(f(x, y)\)</span> 可认为对输入输出同时抽取特征</li>
</ul>
<p>对数线性模型表示的意义为：在条件<span class="math inline">\(x\)</span>以及参数<span class="math inline">\(w\)</span>下发生<span class="math inline">\(y\)</span>的概率，一般<span class="math inline">\(w\)</span>是要学习的参数</p>
<h3 id="分类问题和序列标注问题">分类问题和序列标注问题</h3>
<h4 id="分类问题">分类问题</h4>
<p>分类问题一般是对输入进行建模得到语义编码（如可以使用RNN，CNN进行编码）然后经过分类器将空间映射到分类空间上，最后可通过softmax将权重归一化得到映射到各个分类空间的概率，取概率最大的作为分类。</p>
<h4 id="序列标注问题">序列标注问题</h4>
<p>序列标注问题的重点在于学习序列位置之间的关系，然后解码出最大概率标签路径，比如有<span class="math inline">\(K\)</span>个标签，当输入序列长度为<span class="math inline">\(m\)</span>时，那么就有<span class="math inline">\(K^{m}\)</span>条概率路径，序列标注问题是要从<span class="math inline">\(K^m\)</span>条概率路径中寻找到概率最大的那条路径。NLP中常见的任务，如分词，词性标注，命名体识别都属于序列标注问题。</p>
<h2 id="hmm">HMM</h2>
<p>之前已经说了HMM是<strong>生成模型</strong>，它引入了<strong>一阶马尔科夫假设</strong>：当前状态只与上一状态有关。结合这两点可以得到联合概率</p>
<p><span class="math display">\[p(x_{1}...x_{m}, s_{1}...s_{n}) = \prod_{t}p(s_{t}|s_{t-1})p(x_{t}|s_{t})\]</span></p>
<span class="math inline">\(p(s_{t}|s_{t-1})\)</span>称为状态间的转移概率，<span class="math inline">\(p(x_{t}|s_{t})\)</span>称为发射概率（由隐状态发射成显状态的概率）
<div style="text-align: center">
<img src="/images/posts/crf/hmm.png" alt="">
</div>
<p>由图可知HMM是一个有向图。</p>
<p>HMM的解码部分是求解：<span class="math inline">\(arg \underset{s_{1}...s_{m}}{max}\ p(x_{1}...x_{m}, s_{1}...s_{m})\)</span>, 通常采用Viterbi算法解码</p>
<h3 id="hmm的特点">HMM的特点</h3>
<p>HMM有两个独立性假设：</p>
<ul>
<li>观测序列之间是独立的</li>
<li>当前状态仅依赖于先前的状态</li>
</ul>
<h2 id="memm">MEMM</h2>
<p>Max Entropy Markov Model最大熵马尔可夫模型，在最大熵的基础上引入了一阶马尔科夫假设。 MEMM属于判别式模型，它要学习条件概率</p>
<p><span class="math display">\[p(s_{1}...s_{m}|x_{1}...x_{m}) = \prod_{i=1}^{m}p(s_{i}|s_{1}...s_{i-1}, x_{1}...x_{m})\]</span></p>
<p>由于引入了一阶马尔科夫假设，故当前状态仅于前一状态有关</p>
<p><span class="math display">\[p(s_{1}...s_{m}|x_{1}...x_{m}) = \prod_{i=1}^{m}p(s_{i}|s_{i-1}, x_{1}...x_{m})\]</span></p>
<p>而最大熵模型是对数线性模型从而得到MEMM的模型表达式</p>
<p><span class="math display">\[p(s_{i}|s_{i-1}, x_{1}...x_{m}; w) = \frac{exp(w \cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s_{i}))}{ \sum _{s{}&#39; \epsilon S} exp(w \cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s{}&#39;) ) }\]</span></p>
<p><span class="math inline">\(\phi (x_{1}...x_{m}, i, s_{i-1}, s{}&#39;)\)</span> 是一个特征函数，其中有：</p>
<ul>
<li><span class="math inline">\(i\)</span> 代表当前被标记的位置</li>
<li><span class="math inline">\(s\)</span> 先前的状态</li>
<li><span class="math inline">\(s{}&#39;\)</span> 当前的状态</li>
</ul>
<p>故有</p>
<p><span class="math display">\[\begin{align*}
p(s_{1}...s_{m}|x_{1}...x_{m}) &amp;= \prod_{i=1}^{m} p(s_{i}|s_{i-1}, x_{1}...x_{m}) \\
&amp;= \prod_{i=1}^{m}\frac{exp(w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s_{i}))}{\sum _{s{}&#39;\epsilon S}exp(w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s{}&#39;))} \\
&amp;= \frac{exp(\sum _{i} w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s_{i}))}{\sum _{s{}&#39;\epsilon S}exp(w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s{}&#39;))} \tag{1}
\end{align*}\]</span></p>
<p>MEMM解码部分是计算 <span class="math inline">\(arg \underset{s_{1}...s_{m}}{max}\ p( s_{1}...s_{m}|x_{1}...x_{m})\)</span>，为了好理解我做了一步步简化</p>
<p><span class="math display">\[\begin{align*}
arg \underset{s_{1}...s_{m}}{max}\ p( s_{1}...s_{m}|x_{1}...x_{m}) &amp;= arg \underset{s_{1}...s_{m}}{max}\ \prod_{i=1}^{m}p( s_{i}|s_{i-1} ,x_{1}...x_{m}) \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\ p( s_{i}|s_{i-1}, x_{1}...x_{m} ) \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\frac{exp(w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s_{i}))}{\sum _{s{}&#39;\epsilon S}exp(w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s{}&#39;))} \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\ exp(w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s_{i})) \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\ w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s_{i}) \tag{2}
\end{align*}\]</span></p>
<p>也即是编码等价于求解公式<span class="math inline">\((2)\)</span>，通常用viterbi算法求解，如果不采用viterbi求解它的算法复杂度是<span class="math inline">\(O(K^{m})\)</span> ，采用了viterbi算法可以降到<span class="math inline">\(O(mK^{2})\)</span>，(<span class="math inline">\(K\)</span> 为隐状态数目, <span class="math inline">\(m\)</span>为观测序列长度)</p>
<div style="text-align: center">
<img src="/images/posts/crf/memm.png" alt="">
</div>
<p>如图，MEMM也是有向图模型。</p>
<h3 id="memm的优点">MEMM的优点</h3>
<p>克服了HMM输出独立性问题，通过引入特征函数使得模型比HMM拥有更多信息，而且最大熵则从全局角度来建模，它“保留尽可能多的不确定性，在没有更多的信息时，不擅自做假设”</p>
<h3 id="memm的缺点">MEMM的缺点</h3>
<p>标签偏置(labeling bias)问题，由于MEMM的当前状态只与当前观测以及上一状态有关，导致隐状态中有更少转移的状态拥有的转移概率普遍偏高（是不是一头雾水，再没有更好的解释之前只能继续一头雾水了）简单的说就是MEMM中概率最大路径更容易出现在转移少的状态中。 如何解决这个问题呢？引入全局化特征可以解决标签偏置问题，下文的CRF其实就在MEMM上加入全局化特征从而解决标签偏置问题</p>
<h2 id="crf">CRF</h2>
<p>Conditional Random Forest条件随机场，这里主要讲解线性链（linear-chain）,这里不会牵扯太多概率图的东西（因为我也不会啊:&lt;）还是从对数线性模型出发。 首先要明确的一点是CRF也属于判别模型，所以和MEMM一样需要对</p>
<p><span class="math display">\[p(s_{1}...s_{m}|x_{1}...x_{m})\]</span></p>
<p>建模，CRF也和MEMM一样做了一阶马尔科夫假设，即当前状态只与上一状态有关，但是区别在于CRF的特征采用了全局特征，它把观测序列当做整体来看所以它的特征函数是全局的，它的特征函数为：</p>
<p><span class="math display">\[\varphi (x_{1}...x_{m}, s_{1}...s_{m}) = \sum _{j=1}^{m} \phi (x_{1}...x_{m}, j, s_{j-1}, s_{j})\]</span></p>
<p>其中 <span class="math inline">\(\phi\)</span> 和MEMM的特征函数是一致的，接下来的步骤和MEMM差不多了，只是特征函数变为了<span class="math inline">\(\varphi\)</span>，为了连续性在此再走一遍流程。</p>
<p>CRF的模型表达式为：</p>
<p><span class="math display">\[p(s_{i}|s_{i-1}, x_{1}...x_{m}; w) = \frac{exp(w\cdot \varphi (x_{1}...x_{m}, i, s_{i-1}, s_{i}))}{\sum _{s{}&#39;\epsilon S}exp(w\cdot \varphi (x_{1}...x_{m}, i, s_{i-1}, s{}&#39;))}\]</span></p>
<p>CRF的解码部分是计算 <span class="math inline">\(arg \underset{s_{1}...s_{m}}{max}\ p( s_{1}...s_{m}|x_{1}...x_{m})\)</span>，一步步进行简化</p>
<p><span class="math display">\[\begin{align*}
arg \underset{s_{1}...s_{m}}{max}\ p( s_{1}...s_{m}|x_{1}...x_{m}) &amp;= arg \underset{s_{1}...s_{m}}{max}\prod_{i=1}^{m}p( s_{i}|s_{i-1} ,x_{1}...x_{m}) \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\ p( s_{i}|s_{i-1}, x_{1}...x_{m} ) \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\frac{exp(w\cdot \varphi (x_{1}...x_{m}, i, s_{i-1}, s_{i}))}{\sum _{s{}&#39;\epsilon S}exp(w\cdot \varphi (x_{1}...x_{m}, i, s_{i-1}, s{}&#39;))} \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\ exp(w\cdot \varphi (x_{1}...x_{m}, i, s_{i-1}, s_{i})) \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\ w\cdot \varphi (x_{1}...x_{m}, i, s_{i-1}, s_{i}) \\
&amp;= arg \underset{s_{1}...s_{m}}{max}\ \sum _{j}^{m} w\cdot \phi (x_{1}...x_{m}, i, s_{i-1}, s_{i}) \tag{3}
\end{align*}\]</span></p>
<p>对比一下(2)和(3)可知道CRF和MEMM的区别。和MEMM一样，一般采用viterbi算法来进行解码。</p>
<div style="text-align: center">
<img src="/images/posts/crf/crf.png" alt="">
</div>
<p>由图可知线性链CRF是无向图模型。</p>
<h3 id="crf的优点">CRF的优点</h3>
<p>克服了HMM的输出独立性假设问题以及MEMM的标注偏置问题。</p>
<h2 id="后记">后记</h2>
<p>HMM、MEMM属于有向图模型，贝叶斯网络一般属于有向图。而CRF属于马尔科夫网络属于无向图。所以它们本身属于统计概率图（PGM）的一部分，要想真正弄懂之间的原理和区别还需要系统的学习PGM。</p>
<p>另，由Refrence中可知本文大量引用了Michael Collins教授的tutorial,MC的tutorial通俗易懂，但是有些地方做了简化，如果不详细说明有时也会一头雾水，所以本文主要做了些翻译和修补工作。</p>
<h2 id="refrence">Refrence</h2>
<p>[1] http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf</p>
<p>[2] http://www.cs.columbia.edu/~mcollins/loglinear.pdf</p>
<p>[3] http://www.cs.columbia.edu/~mcollins/crf.pdf</p>
<p>[4] https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&amp;context=cis_papers</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/08/07/python常用魔术方法概览/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/07/python常用魔术方法概览/" itemprop="url">python常用魔术方法概览</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-07T20:39:34+08:00">
                2018-08-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/08/07/python常用魔术方法概览/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/08/07/python常用魔术方法概览/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="构造和初始化">构造和初始化</h2>
<h5 id="init__self-args">__init__(self, args)</h5>
<p>构造函数</p>
<h5 id="new__cls">__new__(cls)</h5>
<p>传入的是类实例</p>
<h5 id="del__self">__del__(self)</h5>
<p>析构函数，调用 <code>del cls</code> 时会被调用</p>
<h2 id="属性访问控制">属性访问控制</h2>
<h5 id="getattr__self-name">__getattr__(self, name)</h5>
<p>如果属性已经定义了那么不会再执行__getattr__()了，而是直接通过访问实例字典返回结果，__getattr__()只在访问未定义的属性时被触发</p>
<h5 id="setattr__self-name-value">__setattr__(self, name, value)</h5>
<p>直接给属性赋值 <code>cls.name = value</code>, 如果该函数内部内部使用<code>self.name = value</code> 时会产生<strong>“无限递归”</strong>的错误，正确的方式应该是 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__setattr__</span><span class="params">(self, name, value)</span>:</span></span><br><span class="line">    self.__dict__[name] = value</span><br></pre></td></tr></table></figure></p>
<h5 id="delattr__self-name">__delattr__(self, name)</h5>
<p><code>del cls.name</code> 时会被调用</p>
<h2 id="描述器对象">描述器对象</h2>
<h5 id="set__self-cls-value">__set__(self, cls, value)</h5>
<p><code>cls.innercls = value</code> 用于类中的其他类对象赋值</p>
<h5 id="get__self-cls">__get__(self, cls)</h5>
<p><code>cls.innercls</code> 返回类中其他对象传回的值</p>
<h5 id="delete__self-cls">__delete__(self, cls)</h5>
<p><code>del cls.innercls</code></p>
<h5 id="综合实例">综合实例</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Meter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a meter.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, value=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        self.value = float(value)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.value</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        self.value = float(value)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foot</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">'''Descriptor for a foot.'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__get__</span><span class="params">(self, instance, owner)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> instance.meter * <span class="number">3.2808</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__set__</span><span class="params">(self, instance, value)</span>:</span></span><br><span class="line">        instance.meter = float(value) / <span class="number">3.2808</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Distance</span><span class="params">(object)</span>:</span></span><br><span class="line">    meter = Meter()</span><br><span class="line">    foot = Foot()</span><br><span class="line"></span><br><span class="line">d = Distance()</span><br><span class="line"><span class="keyword">print</span> d.meter, d.foot  <span class="comment"># 0.0, 0.0</span></span><br><span class="line">d.meter = <span class="number">1</span></span><br><span class="line"><span class="keyword">print</span> d.meter, d.foot  <span class="comment"># 1.0 3.2808</span></span><br><span class="line">d.meter = <span class="number">2</span></span><br><span class="line"><span class="keyword">print</span> d.meter, d.foot  <span class="comment"># 2.0 6.5616</span></span><br></pre></td></tr></table></figure>
<h2 id="自定义容器container">自定义容器(Container)</h2>
<h5 id="len__self">__len__(self)</h5>
<p><code>len(con)</code> 返回容器长度</p>
<h5 id="setitem__self-name-value">__setitem__(self, name, value)</h5>
<p><code>con[name] = value</code> 直接下标赋值</p>
<h5 id="getitem__self-name">__getitem__(self, name)</h5>
<p><code>con[name]</code> 直接下标访问</p>
<h5 id="delitem__name">__delitem__(name)</h5>
<p><code>del con[name]</code> 删除下标</p>
<h5 id="iter__self">__iter__(self)</h5>
<p>使得容器支持迭代器方式访问 <code>for x in con</code></p>
<h5 id="contains__self-item">__contains__(self, item)</h5>
<p><code>name in con</code> 可以返回布尔值</p>
<h5 id="missing__self-name">__missing__(self, name)</h5>
<p>容器中没有name时会被调用</p>
<h2 id="上下文管理">上下文管理</h2>
<p><code>with</code> 关键字可实现上下文(环境)管理</p>
<h5 id="enter__self">__enter__(self)</h5>
<p>进入环境时触发</p>
<h5 id="exit__self-exception_type-exception_value-traceback">__exit__(self, exception_type, exception_value, traceback)</h5>
<p>退出环境时触发，一般用来关闭资源</p>
<h2 id="运算符重载">运算符重载</h2>
<h5 id="eq__self-other">__eq__(self, other)</h5>
<p>重载 <code>=</code></p>
<h5 id="ne__self-other">__ne__(self, other)</h5>
<p>重载 <code>!=</code></p>
<h5 id="lt__self-other">__lt__(self, other)</h5>
<p>重载 <code>&lt;</code></p>
<h5 id="gt__self-other">__gt__(self, other)</h5>
<p>重载 <code>&gt;</code></p>
<h5 id="le__self-other">__le__(self, other)</h5>
<p>重载 <code>&lt;=</code></p>
<h5 id="ge__self-other">__ge__(self, other)</h5>
<p>重载 <code>&gt;=</code></p>
<h2 id="其他">其他</h2>
<h5 id="str__self">__str__(self)</h5>
<p><code>print(cls)</code> 和 <code>str(cls)</code> 时被调用，必须返回字符<code>str</code>类型</p>
<h5 id="repr__self">__repr__(self)</h5>
<p>对实例使用<code>repr()</code>时调用。<code>str()</code>和<code>repr()</code>都是返回一个代表该实例的字符串，主要区别在于: <code>str()</code>的返回值要方便人来看,而<code>repr()</code>的返回值方便计算机看。</p>
<h5 id="call__self-args-kwargs">__call__(self, *args, **kwargs)</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XClass</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, a, b)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line">x = XClass()</span><br><span class="line"><span class="keyword">print</span> <span class="string">'x(1, 2)'</span>, x(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'callable(x)'</span>, callable(x)  <span class="comment"># True</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'add(1, 2)'</span>, add(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">'callable(add)'</span>, callable(add)  <span class="comment"># True</span></span><br></pre></td></tr></table></figure>
<h1 id="refrence">Refrence</h1>
<p>https://segmentfault.com/a/1190000007256392#articleHeader3</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://seanlee97.github.io/2018/07/21/java缓冲池/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="sean lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="明天探索者">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/21/java缓冲池/" itemprop="url">java缓冲池</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-07-21T10:28:25+08:00">
                2018-07-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/programming/" itemprop="url" rel="index">
                    <span itemprop="name">技术日志</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/07/21/java缓冲池/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/07/21/java缓冲池/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="自动装箱拆箱">自动装箱、拆箱</h1>
<p>基本类型都有其对应的包装类型，基本类型与其对应的包装类型间的转换是靠自动装箱 与拆箱完成的</p>
<ul>
<li>基本类型 / 包装类</li>
<li>boolean / Boolean</li>
<li>char / Character</li>
<li>int / Integer</li>
<li>byte / Byte</li>
<li>short / Short</li>
<li>long / Long</li>
<li>float / Float</li>
<li>double / Double</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Integer i = <span class="number">12</span>;   <span class="comment">// 自动装箱，12是基本类型，赋给包装类后自动装箱，相当于掉用了Integer.valueOf(12)</span></span><br><span class="line"><span class="keyword">int</span> j = i; <span class="comment">// 自动拆箱，将Integer转为基本类型int，实际掉用了i.intValue()</span></span><br></pre></td></tr></table></figure>
<h1 id="缓冲池">缓冲池</h1>
<p>new Integer(123) 与 Integer.valueOf(123) 的区别在于， new Integer(123) 每次都会新建一个对象，而 Integer.valueOf(123) 可能会使用缓存对象，因此多次使用 Integer.valueOf(123) 会取得同一个对象的引用。</p>
<p>在 Java 8 中，Integer 缓存池的大小默认为 -128~127。如 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Integer x = <span class="number">127</span>;</span><br><span class="line">Integer y = <span class="number">127</span>;</span><br><span class="line">System.out.println(x == y);  <span class="comment">// True</span></span><br><span class="line"></span><br><span class="line">Integer i = <span class="number">128</span>;</span><br><span class="line">Integer j = <span class="number">128</span>;</span><br><span class="line">System.out.println(i == j);  <span class="comment">// False</span></span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="sean lee" />
            
              <p class="site-author-name" itemprop="name">sean lee</p>
              <p class="site-description motion-element" itemprop="description">NLP / DL / Python / C++ | 爱我所爱</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">24</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index-1.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index-1.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/SeanLee97" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:xmlee97@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://plus.google.com/u/0/114423502510761945752" target="_blank" title="Google">
                      
                        <i class="fa fa-fw fa-google"></i>Google</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/xmlee97" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">sean lee</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>






    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">&nbsp;总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://seanlee97.disqus.com/count.js" async></script>
    

    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
